<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="object detection," />





  <link rel="alternate" href="/atom.xml" title="ljm's blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="http://ov718qcsg.bkt.clouddn.com/blog/icon/dove_128px_1154091_easyicon.net.ico?v=5.1.2" />






<meta name="description" content="一、大体流程1.  训练逻辑&amp;emsp;&amp;emsp;mmdetection的训练逻辑是借助了mmcv中的Runner类，做了一层封装。按照正常的逻辑思考，如果我们要训练一个网络，至少要知道输入数据、模型、优化器、loss等信息，这些信息在tools/train.py以及mmdet/apis/train.py中都有对应的体现，例如在runner构建时传入的model、batch_processor以">
<meta name="keywords" content="object detection">
<meta property="og:type" content="article">
<meta property="og:title" content="mmdetection中的retinanet">
<meta property="og:url" content="https://mingming97.github.io/2019/03/29/mmdetection retinanet/index.html">
<meta property="og:site_name" content="ljm&#39;s blog">
<meta property="og:description" content="一、大体流程1.  训练逻辑&amp;emsp;&amp;emsp;mmdetection的训练逻辑是借助了mmcv中的Runner类，做了一层封装。按照正常的逻辑思考，如果我们要训练一个网络，至少要知道输入数据、模型、优化器、loss等信息，这些信息在tools/train.py以及mmdet/apis/train.py中都有对应的体现，例如在runner构建时传入的model、batch_processor以">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://i.loli.net/2019/03/30/5c9f5b3acd220.png">
<meta property="og:image" content="https://i.loli.net/2019/03/30/5c9f5b3a65c35.png">
<meta property="og:image" content="https://i.loli.net/2019/03/30/5c9f5b3a6df3b.png">
<meta property="og:updated_time" content="2019-03-30T12:05:29.056Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="mmdetection中的retinanet">
<meta name="twitter:description" content="一、大体流程1.  训练逻辑&amp;emsp;&amp;emsp;mmdetection的训练逻辑是借助了mmcv中的Runner类，做了一层封装。按照正常的逻辑思考，如果我们要训练一个网络，至少要知道输入数据、模型、优化器、loss等信息，这些信息在tools/train.py以及mmdet/apis/train.py中都有对应的体现，例如在runner构建时传入的model、batch_processor以">
<meta name="twitter:image" content="https://i.loli.net/2019/03/30/5c9f5b3acd220.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://mingming97.github.io/2019/03/29/mmdetection retinanet/"/>





  <title>mmdetection中的retinanet | ljm's blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript"
  color="0,0,255" opacity="0.3" zIndex="-1" count="30" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/mingming97"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png"></a> 

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ljm's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://mingming97.github.io/2019/03/29/mmdetection retinanet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ljm">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://avatars2.githubusercontent.com/u/30823593?s=400&v=4">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ljm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">mmdetection中的retinanet</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-03-29T14:13:00+08:00">
                2019-03-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/" itemprop="url" rel="index">
                    <span itemprop="name">CV</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  5,792
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  24
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="一、大体流程"><a href="#一、大体流程" class="headerlink" title="一、大体流程"></a>一、大体流程</h2><h3 id="1-训练逻辑"><a href="#1-训练逻辑" class="headerlink" title="1.  训练逻辑"></a>1.  训练逻辑</h3><p>&emsp;&emsp;mmdetection的训练逻辑是借助了mmcv中的Runner类，做了一层封装。按照正常的逻辑思考，如果我们要训练一个网络，至少要知道输入数据、模型、优化器、loss等信息，这些信息在<code>tools/train.py</code>以及<code>mmdet/apis/train.py</code>中都有对应的体现，例如在runner构建时传入的model、batch_processor以及optimizer，就分别对应了模型、loss、以及优化器，而runner.run调用时传入的data_loaders则对应了输入数据的部分。</p>
<p>&emsp;&emsp;值得注意的是batch_processor，它所做的其实就是通过喂入数据进行前馈计算得到loss，然后返回一个对应的记录了各种loss信息以及数据信息的字典，而这个返回的loss信息的处理则调用了parse_losses函数。这个函数所做的其实就是将一个字典中所有的loss字段分别记录，最后相加得到最终的loss。知道了这个过程，就可以知道，在计算loss的时候就已经要乘上每一项对应的系数，返回的时候也要返回一个对应不同类loss名称的字典。</p>
<h3 id="2-技术细节"><a href="#2-技术细节" class="headerlink" title="2. 技术细节"></a>2. 技术细节</h3><p>&emsp;&emsp;此部分可以参照<a href="https://github.com/open-mmlab/mmdetection" target="_blank" rel="external">mmdetection</a>的<a href="https://github.com/open-mmlab/mmdetection/blob/master/TECHNICAL_DETAILS.md" target="_blank" rel="external">technical details</a>中的内容。在mmdetection中，构成model的有四类组件</p>
<ul>
<li><p>backbone：一般用于feature map的提取，例如resnet，vgg。</p>
</li>
<li><p>neck：在feature map和head之间的网络，例如FPN。</p>
</li>
<li><p>head：用于具体任务的网络，例如bbox regression、mask prediction。</p>
</li>
<li><p>roi extractor：从feature map进一步提取特征的部分，例如RoI Align。</p>
</li>
</ul>
<p>&emsp;&emsp;而把这些部分组合起来的就是detector，mmdetection中有两个典型的detector，一个是<code>SingleStageDetector</code>，一个是<code>TwoStageDetector</code>。一般一个detector中要实现四个抽象方法</p>
<ul>
<li><p><code>extract_feat()</code>：给出一个batch的图片，tensor的shape是(n, c, h, w)，提取出feature map。</p>
</li>
<li><p><code>forward_train()</code>：前馈计算得到loss。</p>
</li>
<li><p><code>simple_test()</code>：单个scale图片的测试模式。</p>
</li>
<li><p><code>aug_test()</code>：带有数据增强的测试模式。</p>
</li>
</ul>
<p>&emsp;&emsp;下面将围绕retinanet涉及到的组件进行讲解。</p>
<h2 id="二、网络结构"><a href="#二、网络结构" class="headerlink" title="二、网络结构"></a>二、网络结构</h2><h3 id="1-backbone"><a href="#1-backbone" class="headerlink" title="1. backbone"></a>1. backbone</h3><p>&emsp;&emsp;retinanet用到的backbone有res50，res101两种，当然还有ResNeXt等较新的网络。以res50为例，其有关backbone配置的部分如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">backbone=dict(</div><div class="line">    type=<span class="string">'ResNet'</span>,</div><div class="line">    depth=<span class="number">50</span>,</div><div class="line">    num_stages=<span class="number">4</span>,</div><div class="line">    out_indices=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>),</div><div class="line">    frozen_stages=<span class="number">1</span>,</div><div class="line">    style=<span class="string">'pytorch'</span>)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;其中depth，num_stages都是resnet中常见的配置，out_indices也是指输出的特征图，与stage对应，此处代表C2，C3，C4，C5。而C2，C3，C4，C5分别对应resnet中第conv2_x、conv3_x、conv4_x、conv5_x块的输出，见下图</p>
<p><img src="https://i.loli.net/2019/03/30/5c9f5b3acd220.png" alt=""></p>
<p>&emsp;&emsp;有一些关于resnet的细节。conv3_x、conv4_x、conv5_x的第一个block中会有一个stride为2的卷积用于减小特征图大小，在caffe的实现中，是在第一个1$\times$1的卷积处，而pytorch的实现中是在中间3$\times$3的卷积处，在mmdetection的代码中都有对应体现。另一个就是<code>frozen_stages=1</code>，由于要对resnet做finetune，所以要冻结一部分浅层的参数，此处默认冻结conv1，而<code>fronzen_stages</code>就是控制<code>frozen_stages</code>之前所有stage的卷积块都会被冻结，在这里也就是冻结第一个stage，conv2_x。除此之外还有一点就是冻结了网络中所有的<code>BN</code>层，因为batch数目太小了，加<code>BN</code>没有意义。</p>
<p>&emsp;&emsp;从代码可以看出，需要保存的特征图放在了一个list中。在retinanet里，backbone的输出就是四个特征图，[C2, C3, C4, C5]。</p>
<h3 id="2-neck"><a href="#2-neck" class="headerlink" title="2. neck"></a>2. neck</h3><p>&emsp;&emsp;neck部分使用的是FPN。configs中相关配置如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">neck=dict(</div><div class="line">    type=<span class="string">'FPN'</span>,</div><div class="line">    in_channels=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</div><div class="line">    out_channels=<span class="number">256</span>,</div><div class="line">    start_level=<span class="number">1</span>,</div><div class="line">    add_extra_convs=<span class="keyword">True</span>,</div><div class="line">    num_outs=<span class="number">5</span>)</div></pre></td></tr></table></figure>
<ul>
<li>in_channels：输入特征图的channel数。</li>
<li>out_channels：输出特征图的channel数。</li>
<li>start_level：起始特征图的层数，例如start_level=1，意思就是不会使用C2，lateral connection只需要连接C3、C4、C5。</li>
<li>add_extra_convs：添加额外卷积层，在retinanet中是用于生成P6和P7的conv。</li>
<li>num_outs：输出特征图个数，在retinanet中是P3、P4、P5、P6、P7。</li>
</ul>
<p>整体bottom-up以及top-down过程如下图所示</p>
<p><img src="https://i.loli.net/2019/03/30/5c9f5b3a65c35.png" alt=""></p>
<p>在经过neck后，会有五个尺度的特征图，同样保存在了一个list中，输出是[P3, P4, P5, P6, P6]。</p>
<h3 id="3-head"><a href="#3-head" class="headerlink" title="3. head"></a>3. head</h3><h4 id="（1）retinanet的head部分概述"><a href="#（1）retinanet的head部分概述" class="headerlink" title="（1）retinanet的head部分概述"></a>（1）retinanet的head部分概述</h4><p>&emsp;&emsp;在看这一部分之前，需要先了解一个重要的函数，这个函数屡次被用到，那就是<code>mmdet/core/utils/misc.py</code>中的<code>multi_apply()</code>函数，代码如下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_apply</span><span class="params">(func, *args, **kwargs)</span>:</span></div><div class="line">    pfunc = partial(func, **kwargs) <span class="keyword">if</span> kwargs <span class="keyword">else</span> func</div><div class="line">    map_results = map(pfunc, *args)</div><div class="line">    <span class="keyword">return</span> tuple(map(list, zip(*map_results)))</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;这个函数的作用其实就是将多个序列中的每一组元素都通过func函数，再将所得结果转置后返回。这样解释可能比较抽象，举一个例子：假如有两个列表list1，list2，我们要计算这两个列表的element-wise sum和element-wise product，我们可以通过一个函数同时返回两个数的和和差，如<code>lambda x, y: (x + y, x * y)</code>。再使用map函数，也就是：<code>map(lambda x, y:(x + y, x * y), list1, list2)</code>，但是这样的结果是按照<code>[(sum, product), (sum, product), ...]</code>这样的形式组织的，所以要将它们转置，这样才能让结果中的和在一个列表中，差在一个列表中。</p>
<p>&emsp;&emsp;而用到这个函数则涉及到一个设计思想，那就是将问题按照不同的角度去分解。无论是在<code>mmdet/models/anchor_heads/anchor_head.py</code>还是在<code>mmdetection/mmdet/core/anchor/anchor_target</code>中，都能看到很多<code>_single()</code>结尾的函数，这样的函数解决的就是分解后的一个小问题。而将一个列表中每一个元素经过<code>multi_apply()</code>函数，再将结果组合起来，就得到了一个大问题的结果。具体到retinanet中，主要分解的角度有两个，一个是图片，另一个是特征图的尺度。这个角度的意思其实就是说在流程进行中，涉及到的数据的第一个维度的含义，第一种是图片数目，也就是一个batch中图片的数目作为第一个维度；第二种是特征图尺度的数目，在retinanet中有五个特征图，也就是第一个维度等于5。</p>
<p>&emsp;&emsp;需要逐图片解决的就是每个图片有关anchor的计算，比如anchor的assign，训练样本的sample，和label的获得等。而这一步解决后返回的结果需要是按特征图大小作为第一维度的，因为在<code>mmdet/models/retina_head.py</code>中的RetinaHead类完成了类别得分<code>cls_scores</code>，以及回归预测结果<code>bbox_preds</code>的计算，使用了<code>forward_single()</code>函数，这个函数是在RetinaHead的父类AnchorHead中被调用的，它的<code>forward()</code>只有一句话，那就是<code>return multi_apply(self.forward_single, feats)</code>，也就是说得到的<code>cls_scores</code>的shape是<code>[feat_size_num, batch_size, cls_num*A, N, M]</code>，<code>bbox_preds</code>的shape是<code>[feat_size_num, batch_size, 4*A, N, M]</code>（A是同一个中心不同大小不同长宽比的anchor数）。这两部分都不是严格的Tensor，因为不同feat_size下的N和M不同，因此需要将feat_size_num个Tensor放在一个list中。所以在计算的时候，要逐个feat_size进行计算，也就是<code>loss_single()</code>所完成的计算。</p>
<p>&emsp;&emsp;<code>RetinaHead</code>同样涉及到配置字典，下面是具体参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">bbox_head=dict(</div><div class="line">    type=<span class="string">'RetinaHead'</span>,</div><div class="line">    num_classes=<span class="number">81</span>,</div><div class="line">    in_channels=<span class="number">256</span>,</div><div class="line">    stacked_convs=<span class="number">4</span>,</div><div class="line">    feat_channels=<span class="number">256</span>,</div><div class="line">    octave_base_scale=<span class="number">4</span>,</div><div class="line">    scales_per_octave=<span class="number">3</span>,</div><div class="line">    anchor_ratios=[<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>],</div><div class="line">    anchor_strides=[<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">128</span>],</div><div class="line">    target_means=[<span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>],</div><div class="line">    target_stds=[<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]))</div></pre></td></tr></table></figure>
<ul>
<li>num_classes：类别数，此处是默认算上背景的类别数，如果使用sigmoid分类，那样one hot向量全为0就可以代表背景类，就会将num_classes-1，具体代码可以参照<code>mmdet/models/anchor_heads/anchor_head.py</code>中<code>AnchorHead</code>类的<code>__init__()</code>方法，第65到68行。</li>
<li>in_channels：输入的特征图的channel数</li>
<li>stacked_convs：在分类分支和回归分支中堆叠起来的conv层数。</li>
<li>feat_channels：在堆叠起来的conv层中，特征的channel数</li>
<li>octave_base_scale：用于计算anchor_scales的参数，具体在下面解释</li>
<li>scales_per_octave：同上</li>
<li>anchor_ratios：anchor的aspect ratio</li>
<li>anchor_strides：在另一篇博文中有解释，可参照<a href="https://mingming97.github.io/2019/03/26/anchor%20in%20object%20detection">这篇博文</a></li>
<li>target_means，target_stds：在rpn中有用到，用于测试阶段proposals的获得。retinanet不涉及。</li>
</ul>
<h4 id="（2）cls-scores以及bbox-preds的计算"><a href="#（2）cls-scores以及bbox-preds的计算" class="headerlink" title="（2）cls_scores以及bbox_preds的计算"></a>（2）cls_scores以及bbox_preds的计算</h4><p>&emsp;&emsp;这一部分可以参照网络图来看<code>RetinaHead</code>中的代码</p>
<p><img src="https://i.loli.net/2019/03/30/5c9f5b3a6df3b.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_init_layers</span><span class="params">(self)</span>:</span></div><div class="line">    self.relu = nn.ReLU(inplace=<span class="keyword">True</span>)</div><div class="line">    self.cls_convs = nn.ModuleList()</div><div class="line">    self.reg_convs = nn.ModuleList()</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(self.stacked_convs):</div><div class="line">        chn = self.in_channels <span class="keyword">if</span> i == <span class="number">0</span> <span class="keyword">else</span> self.feat_channels</div><div class="line">        self.cls_convs.append(</div><div class="line">            nn.Conv2d(chn, self.feat_channels, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>))</div><div class="line">        self.reg_convs.append(</div><div class="line">            nn.Conv2d(chn, self.feat_channels, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>))</div><div class="line">    self.retina_cls = nn.Conv2d(</div><div class="line">        self.feat_channels,</div><div class="line">        self.num_anchors * self.cls_out_channels,</div><div class="line">        <span class="number">3</span>,</div><div class="line">        padding=<span class="number">1</span>)</div><div class="line">    self.retina_reg = nn.Conv2d(</div><div class="line">        self.feat_channels, self.num_anchors * <span class="number">4</span>, <span class="number">3</span>, padding=<span class="number">1</span>)</div></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_single</span><span class="params">(self, x)</span>:</span></div><div class="line">    cls_feat = x</div><div class="line">    reg_feat = x</div><div class="line">    <span class="keyword">for</span> cls_conv <span class="keyword">in</span> self.cls_convs:</div><div class="line">        cls_feat = self.relu(cls_conv(cls_feat))</div><div class="line">    <span class="keyword">for</span> reg_conv <span class="keyword">in</span> self.reg_convs:</div><div class="line">        reg_feat = self.relu(reg_conv(reg_feat))</div><div class="line">    cls_score = self.retina_cls(cls_feat)</div><div class="line">    bbox_pred = self.retina_reg(reg_feat)</div><div class="line">    <span class="keyword">return</span> cls_score, bbox_pred</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;定义了几个堆叠层，与上面网络结构的描述基本一致。实现了<code>forward_single()</code>，这里注意到分类分支和回归分支是共享特征图的。<code>forward_single()</code>是用于处理一个尺度的特征图的，所以这个函数将会在<code>multi_apply()</code>中被使用，生成不同尺度特征图的分类和回归结果。因此输出的cls_scores，bbox_preds也是一个列表，<code>cls_scores</code>的存储格式是<code>[shape([batch_size, cls_num*A, H1, W1]), shape([batch_size, cls_num*A, H2, W2]), ...]</code>，<code>bbox_preds</code>的存储格式是<code>[shape([batch_size, 4*A, H1, W1]), shape([batch_size, 4*A, H2, W2]), ...]</code>。</p>
<h4 id="（3）anchor的获得"><a href="#（3）anchor的获得" class="headerlink" title="（3）anchor的获得"></a>（3）anchor的获得</h4><p>&emsp;&emsp;anchor的获得同样可以参照<a href="https://mingming97.github.io/2019/03/26/anchor%20in%20object%20detection">这篇博文</a>，这里再结合代码细致说明一下anchor的生成过程。base_anchor的生成在那篇博文中解释的很详尽，需要解释的是滑动生成所有anchor的部分，这一部分的代码如下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">grid_anchors</span><span class="params">(self, featmap_size, stride=<span class="number">16</span>, device=<span class="string">'cuda'</span>)</span>:</span></div><div class="line">    base_anchors = self.base_anchors.to(device)</div><div class="line"></div><div class="line">    feat_h, feat_w = featmap_size</div><div class="line">    shift_x = torch.arange(<span class="number">0</span>, feat_w, device=device) * stride</div><div class="line">    shift_y = torch.arange(<span class="number">0</span>, feat_h, device=device) * stride</div><div class="line">    shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)</div><div class="line">    shifts = torch.stack([shift_xx, shift_yy, shift_xx, shift_yy], dim=<span class="number">-1</span>)</div><div class="line">    shifts = shifts.type_as(base_anchors)</div><div class="line">    <span class="comment"># first feat_w elements correspond to the first row of shifts</span></div><div class="line">    <span class="comment"># add A anchors (1, A, 4) to K shifts (K, 1, 4) to get</span></div><div class="line">    <span class="comment"># shifted anchors (K, A, 4), reshape to (K*A, 4)</span></div><div class="line"></div><div class="line">    all_anchors = base_anchors[<span class="keyword">None</span>, :, :] + shifts[:, <span class="keyword">None</span>, :]</div><div class="line">    all_anchors = all_anchors.view(<span class="number">-1</span>, <span class="number">4</span>)</div><div class="line">    <span class="comment"># first A rows correspond to A anchors of (0, 0) in feature map,</span></div><div class="line">    <span class="comment"># then (0, 1), (0, 2), ...</span></div><div class="line">    <span class="keyword">return</span> all_anchors</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;<code>shift_x</code>以及<code>shift_y</code>就是坐标偏移的大小，很好理解，那么如何通过这个生成x方向的偏移和y方向的偏移呢，这就用到了<code>_meshgrid()</code>这个函数。这个函数如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_meshgrid</span><span class="params">(self, x, y, row_major=True)</span>:</span></div><div class="line">    xx = x.repeat(len(y))</div><div class="line">    yy = y.view(<span class="number">-1</span>, <span class="number">1</span>).repeat(<span class="number">1</span>, len(x)).view(<span class="number">-1</span>)</div><div class="line">    <span class="keyword">if</span> row_major:</div><div class="line">        <span class="keyword">return</span> xx, yy</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> yy, xx</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;这个函数看似复杂，其实结果很有规律，就是生成x方向所有的偏移和y方向上所有的偏移，之前的<code>shift_x</code>和<code>shift_y</code>仅仅是一组偏移。可以想象一个网格中，顶层有一行数字是x的偏移，那么要生成所有行x的偏移就要将x的偏移重复y的长度次；有一列数字是y的偏移，要生成所有列y的偏移就要讲y的偏移重复x的长度次，再将结果flat后输出，就得到了所有的偏移量，也就是<code>shift_xx</code>以及<code>shift_yy</code>。</p>
<p>&emsp;&emsp;之后将<code>shift_xx, shift_yy</code>叠起来，其实就生成了<code>shift_x</code>和<code>shift_y</code>的笛卡儿积，其形状是<code>[2, H*W]</code>，因为base_anchor左上角和右下角的坐标是同步平移的，所以最终将两组<code>shift_xx, shift_yy</code>堆叠起来得到了形状是<code>[4, H*W]</code>的<code>shifts</code>。之后利用了广播机制，每个点有A个anchor，A个anchor中每个anchor的偏移量都是相同的，所以将对应需要广播的维度设为1，最终得到H*W*A个anchor的坐标。</p>
<p>&emsp;&emsp;这里面还有一个<code>valid_flags</code>的获得，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid_flags</span><span class="params">(self, featmap_size, valid_size, device=<span class="string">'cuda'</span>)</span>:</span></div><div class="line">    feat_h, feat_w = featmap_size</div><div class="line">    valid_h, valid_w = valid_size</div><div class="line">    <span class="keyword">assert</span> valid_h &lt;= feat_h <span class="keyword">and</span> valid_w &lt;= feat_w</div><div class="line">    valid_x = torch.zeros(feat_w, dtype=torch.uint8, device=device)</div><div class="line">    valid_y = torch.zeros(feat_h, dtype=torch.uint8, device=device)</div><div class="line">    valid_x[:valid_w] = <span class="number">1</span></div><div class="line">    valid_y[:valid_h] = <span class="number">1</span></div><div class="line">    valid_xx, valid_yy = self._meshgrid(valid_x, valid_y)</div><div class="line">    valid = valid_xx &amp; valid_yy</div><div class="line">    valid = valid[:, <span class="keyword">None</span>].expand(</div><div class="line">        valid.size(<span class="number">0</span>), self.num_base_anchors).contiguous().view(<span class="number">-1</span>)</div><div class="line">    <span class="keyword">return</span> valid</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;首先计算出合法的h和w的边界，然后将x方向上合法的中心部分设为1，y方向上合法的中心部分设为1，再利用<code>_meshgrid</code>得到两个方向上所有的合法情况，与操作得到两个方向都合法的点，由于每个点有A个框，一个框合法余下的暂时都算作合法，expand每个点的结果，最终flat得到一个<code>shape([H*W*A])</code>的Tensor，记录着每个框的合法情况。</p>
<p>&emsp;&emsp;不同尺度的anchor及其valid_flag的获取是在<code>mmdet/models/anchor_heads/anchor_head.py</code>中<code>AnchorHead</code>类的方法<code>get_anchors()</code>中得到。最终会得到一个list[list[Tensors]]，最外层是图片个数，再内一层是尺度个数，里面的Tensors的shape是<code>[H*W*4, 4]</code>，其中H和W代表对应尺度特征图的高和宽。</p>
<h4 id="（4）Anchor-target的获取"><a href="#（4）Anchor-target的获取" class="headerlink" title="（4）Anchor target的获取"></a>（4）Anchor target的获取</h4><h5 id="①-anchor-target-mmdet-core-anchor-anchor-target-py"><a href="#①-anchor-target-mmdet-core-anchor-anchor-target-py" class="headerlink" title="① anchor_target (mmdet/core/anchor/anchor_target.py)"></a>① anchor_target (mmdet/core/anchor/anchor_target.py)</h5><p>&emsp;&emsp;得到了anchor后要通过两步来得到训练的目标。</p>
<ol>
<li>Assign：把各个anchors分配给gt box的过程</li>
<li>Sample：从所有的bbox中sample出训练样本的过程。</li>
</ol>
<p>&emsp;&emsp;1个batch中每张图片的训练目标的获取都是调用<code>mmdet/core/anchor/anchor_target.py</code>中<code>anchor_target()</code>函数得到的。下面来大致看一下这个函数干了什么，再细致看Assign和Sample的过程。</p>
<p>&emsp;&emsp;首先获取了每张图片中，每种尺度anchor的数目</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">num_level_anchors = [anchors.size(<span class="number">0</span>) <span class="keyword">for</span> anchors <span class="keyword">in</span> anchor_list[<span class="number">0</span>]]</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;然后将每张图片中所有尺度的anchor放在一起，例如：有两个尺度，第一个尺度有20个anchor，其对应Tensor的形状是<code>[20, 4]</code>，第二个尺度有10个anchor，对应Tensor的形状是<code>[10, 4]</code>，那么会将该图片中所有尺度的anchor放在一起，变成一个<code>[30, 4]</code>的anchor。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_imgs):</div><div class="line">    <span class="keyword">assert</span> len(anchor_list[i]) == len(valid_flag_list[i])</div><div class="line">    anchor_list[i] = torch.cat(anchor_list[i])</div><div class="line">    valid_flag_list[i] = torch.cat(valid_flag_list[i])</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;得到了每张图的所有anchor，就逐个图片调用<code>anchor_target_single()</code>函数，计算得到每张图片的每个anchor的label及其对应的weights（后面会解释），到对应gt box的delta值及其weights，以及正样本和负样本的下标。注意此时结果是一个list[Tensor]，第一维度是图片。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">(all_labels, all_label_weights, all_bbox_targets, all_bbox_weights,</div><div class="line"> pos_inds_list, neg_inds_list) = multi_apply(</div><div class="line">     anchor_target_single,</div><div class="line">     anchor_list,</div><div class="line">     valid_flag_list,</div><div class="line">     gt_bboxes_list,</div><div class="line">     gt_bboxes_ignore_list,</div><div class="line">     gt_labels_list,</div><div class="line">     img_metas,</div><div class="line">     target_means=target_means,</div><div class="line">     target_stds=target_stds,</div><div class="line">     cfg=cfg,</div><div class="line">     label_channels=label_channels,</div><div class="line">     sampling=sampling,</div><div class="line">     unmap_outputs=unmap_outputs)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;接下来计算所有图片中所有正样本以及负样本的个数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">num_total_pos = sum([max(inds.numel(), <span class="number">1</span>) <span class="keyword">for</span> inds <span class="keyword">in</span> pos_inds_list])</div><div class="line">num_total_neg = sum([max(inds.numel(), <span class="number">1</span>) <span class="keyword">for</span> inds <span class="keyword">in</span> neg_inds_list])</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;最后将所有以图片为第一维度的结果，通过函数<code>images_to_levels()</code>，转换成以特征图尺度个数为第一维度的结果，供loss计算使用。具体做法如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">labels_list = images_to_levels(all_labels, num_level_anchors)</div><div class="line">label_weights_list = images_to_levels(all_label_weights, num_level_anchors)</div><div class="line">bbox_targets_list = images_to_levels(all_bbox_targets, num_level_anchors)</div><div class="line">bbox_weights_list = images_to_levels(all_bbox_weights, num_level_anchors)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;下面是<code>image_to_levels()</code>的实现，首先将列表中每个img的结果堆叠起来，最后再将结果按每个尺度中anchor个数切片即可。此处以bbox_targets为例，假如一个batch_size有2张图片，一共有三个尺度的特征图分别有30、20、10个anchor。 那么一开始的输入就是<code>[shape([60, 4]), shape([60, 4])]</code>，将其堆叠起来就能得到<code>shape([2, 60, 4])</code>的Tensor，之后再按照特征图个数切片，最后得到<code>[shape([2, 30, 4]), shape([2, 20, 4]), shape([2, 10, 4])]</code>的list。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">images_to_levels</span><span class="params">(target, num_level_anchors)</span>:</span></div><div class="line">    <span class="string">"""Convert targets by image to targets by feature level.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    [target_img0, target_img1] -&gt; [target_level0, target_level1, ...]</span></div><div class="line"><span class="string">    """</span></div><div class="line">    target = torch.stack(target, <span class="number">0</span>)</div><div class="line">    level_targets = []</div><div class="line">    start = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> num_level_anchors:</div><div class="line">        end = start + n</div><div class="line">        level_targets.append(target[:, start:end].squeeze(<span class="number">0</span>))</div><div class="line">        start = end</div><div class="line">    <span class="keyword">return</span> level_targets</div></pre></td></tr></table></figure></p>
<h5 id="②-anchor-target-single-mmdet-core-anchor-anchor-target-py"><a href="#②-anchor-target-single-mmdet-core-anchor-anchor-target-py" class="headerlink" title="② anchor_target_single (mmdet/core/anchor/anchor_target.py)"></a>② anchor_target_single (mmdet/core/anchor/anchor_target.py)</h5><p>&emsp;&emsp;在这里只需要关注一张图中所有的anchor即可，首先用<code>anchors = flat_anchors[inside_flags, :]</code>来将所有有效的anchor提取出来，以减少计算量。而为了与<code>cls_scores</code>和<code>bbox_preds</code>的形状相符合，最后所有结果还要unmap回函数输入flat_anchors中。</p>
<p>&emsp;&emsp;再然后使用<code>Assigner</code>和<code>Sampler</code>来获取训练样本，这里内容较多，决定单开贴另说。只提一个小细节，由于使用了focal loss，一定程度解决了前景背景类别不均衡问题，所以sample的时候sample了全部的背景样本。对于其他的detector则需要采取一定措施限制负样本的个数，保持正负样本比例。</p>
<p>&emsp;&emsp;经过这两个部分后，就得到了一个<code>SamplingResult</code> ，这个类定义在了<code>mmdet/core/bbox/samplers/sampling_result.py</code>，里面主要保存了如下内容</p>
<ul>
<li>pos_inds：正样本的下标</li>
<li>neg_inds：负样本的下标</li>
<li>pos_bboxes：正样本的bbox坐标</li>
<li>neg_bboxes：负样本的bbox坐标</li>
<li>pos_is_gt：正样本的bbox是否就是gt_bbox</li>
<li>num_gts：gt_bbox的个数</li>
<li>pos_assigned_gt_inds：正样本所对应的gt bbox在gt_bboxes中的下标</li>
<li>pos_gt_bboxes：每个正样本对应的gt_bbox的坐标</li>
<li>pos_gt_labels：每个正样本对应的gt的label</li>
</ul>
<p>&emsp;&emsp;之后通过这些信息来计算target和weight，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">num_valid_anchors = anchors.shape[<span class="number">0</span>]</div><div class="line">bbox_targets = torch.zeros_like(anchors)</div><div class="line">bbox_weights = torch.zeros_like(anchors)</div><div class="line">labels = anchors.new_zeros(num_valid_anchors, dtype=torch.long)</div><div class="line">label_weights = anchors.new_zeros(num_valid_anchors, dtype=torch.float)</div><div class="line"></div><div class="line">pos_inds = sampling_result.pos_inds</div><div class="line">neg_inds = sampling_result.neg_inds</div><div class="line"><span class="keyword">if</span> len(pos_inds) &gt; <span class="number">0</span>:</div><div class="line">    pos_bbox_targets = bbox2delta(sampling_result.pos_bboxes,</div><div class="line">                                  sampling_result.pos_gt_bboxes,</div><div class="line">                                  target_means, target_stds)</div><div class="line">    bbox_targets[pos_inds, :] = pos_bbox_targets</div><div class="line">    bbox_weights[pos_inds, :] = <span class="number">1.0</span></div><div class="line">    <span class="keyword">if</span> gt_labels <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        labels[pos_inds] = <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        labels[pos_inds] = gt_labels[sampling_result.pos_assigned_gt_inds]</div><div class="line">    <span class="keyword">if</span> cfg.pos_weight &lt;= <span class="number">0</span>:</div><div class="line">        label_weights[pos_inds] = <span class="number">1.0</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        label_weights[pos_inds] = cfg.pos_weight</div><div class="line"><span class="keyword">if</span> len(neg_inds) &gt; <span class="number">0</span>:</div><div class="line">    label_weights[neg_inds] = <span class="number">1.0</span></div></pre></td></tr></table></figure>
<p>&emsp;&emsp;注意到这里面的bbox_targets和label结果中都对应了weights且shape与它们自己相同，这些weights默认都是0。对于bbox_targets_weights，需要将正样本weight设为1，而对于label，需要将正负样本的weight都设为1。注意到这里面不一定正负样本加起来就是全部valid anchor，因为assign过程中有一部分anchor会根据IoU大小被忽略，所以正负样本都要特地赋值为1。</p>
<p>&emsp;&emsp;最后就是将结果对应回<code>flat_anchors</code>，调用了同一文件中的<code>unmap()</code>函数。这个unmap的过程很简单，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> unmap_outputs:</div><div class="line">    num_total_anchors = flat_anchors.size(<span class="number">0</span>)</div><div class="line">    labels = unmap(labels, num_total_anchors, inside_flags)</div><div class="line">    label_weights = unmap(label_weights, num_total_anchors, inside_flags)</div><div class="line">    <span class="keyword">if</span> label_channels &gt; <span class="number">1</span>:</div><div class="line">        labels, label_weights = expand_binary_labels(</div><div class="line">            labels, label_weights, label_channels)</div><div class="line">    bbox_targets = unmap(bbox_targets, num_total_anchors, inside_flags)</div><div class="line">    bbox_weights = unmap(bbox_weights, num_total_anchors, inside_flags)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;这是unmap函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">unmap</span><span class="params">(data, count, inds, fill=<span class="number">0</span>)</span>:</span></div><div class="line">    <span class="string">""" Unmap a subset of item (data) back to the original set of items (of</span></div><div class="line"><span class="string">    size count) """</span></div><div class="line">    <span class="keyword">if</span> data.dim() == <span class="number">1</span>:</div><div class="line">        ret = data.new_full((count, ), fill)</div><div class="line">        ret[inds] = data</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        new_size = (count, ) + data.size()[<span class="number">1</span>:]</div><div class="line">        ret = data.new_full(new_size, fill)</div><div class="line">        ret[inds, :] = data</div><div class="line">    <span class="keyword">return</span> ret</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;这里要注意一个细节，<code>label_channels &gt; 1</code>的情况下就要调用<code>expand_binary_label()</code>函数。<code>label_channels</code>的值其实是在<code>mmdet/models/anchor_heads/anchor_head.py</code>中计算的，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">label_channels = self.cls_out_channels <span class="keyword">if</span> self.use_sigmoid_cls <span class="keyword">else</span> <span class="number">1</span></div></pre></td></tr></table></figure>
<p>&emsp;&emsp;含义就是如果使用sigmoid得到分类结果（每个channel都是一个二分类，属于该类目标值为1，不属于该类目标值为0），那么label_channels就是分类结果的channel数；否则为1。retinanet要使用focal loss，自然每个channel都是一个二分类，所以这里label_channels肯定大于1。这样<code>expand_binary_label()</code>的作用就清楚了，之前每个anchor的label都是对应label的序号，现在要将这个序号转化为一个one-hot的vector（背景类为全0的vector），以下是<code>expand_binary_label()</code>的实现，其实就是一个将序号转化为one-hot vector的过程，并不复杂。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand_binary_labels</span><span class="params">(labels, label_weights, label_channels)</span>:</span></div><div class="line">    bin_labels = labels.new_full((labels.size(<span class="number">0</span>), label_channels), <span class="number">0</span>)</div><div class="line">    inds = torch.nonzero(labels &gt;= <span class="number">1</span>).squeeze()</div><div class="line">    <span class="keyword">if</span> inds.numel() &gt; <span class="number">0</span>:</div><div class="line">        bin_labels[inds, labels[inds] - <span class="number">1</span>] = <span class="number">1</span></div><div class="line">    bin_label_weights = label_weights.view(<span class="number">-1</span>, <span class="number">1</span>).expand(</div><div class="line">        label_weights.size(<span class="number">0</span>), label_channels)</div><div class="line">    <span class="keyword">return</span> bin_labels, bin_label_weights</div></pre></td></tr></table></figure>
<h4 id="5-loss的计算"><a href="#5-loss的计算" class="headerlink" title="(5) loss的计算"></a>(5) loss的计算</h4><p>&emsp;&emsp;loss的计算就是逐个尺度进行计算的过程，调用了<code>multi_apply()</code>函数将每个尺度下的预测和标签信息等传入<code>loss_single()</code>进行计算。如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">losses_cls, losses_reg = multi_apply(</div><div class="line">    self.loss_single,</div><div class="line">    cls_scores,</div><div class="line">    bbox_preds,</div><div class="line">    labels_list,</div><div class="line">    label_weights_list,</div><div class="line">    bbox_targets_list,</div><div class="line">    bbox_weights_list,</div><div class="line">    num_total_samples=num_total_samples,</div><div class="line">    cfg=cfg)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;这些传入的变量都是在之前的步骤中得到的，不难知道他们代表的含义。除了<code>num_total_samples</code>需要解释一下，表面看这个变量的含义是sample出的总样本的个数，但是它的计算方式却是<code>num_total_samples = (num_total_pos if self.use_focal_loss else num_total_pos + num_total_neg)</code>。为什么在使用focal loss的时候仅仅取正样本呢，这是因为这个变量在loss的计算中作为<code>avg_factor</code>使用，类似于loss的平均值，其它的检测方式中都有对负样本的sample过程，这样正负样本的和就不会很多。但是在focal loss中使用的是<code>PseudoSampler</code>，近乎于取了全部的负样本，这样正负样本的和就会非常大，loss的和除完这个数会非常小，使得训练无法进行。这个细节在focal loss的paper中有提到，如下</p>
<blockquote>
<p>The total focal loss of an image is computed as the sum of the focal loss over all ~100k anchors, <em>normalized by the number of anchors assigned to a ground-truth box</em>. </p>
</blockquote>
<p>&emsp;&emsp;下面就具体看一下一个尺度的loss的计算，这些是在<code>mmdet/models/anchor_heads/anchor_head.py</code>中的<code>loss_single()</code>函数中计算的。下面逐个部分看一下loss的计算。</p>
<h5 id="①-分类损失"><a href="#①-分类损失" class="headerlink" title="① 分类损失"></a>① 分类损失</h5><p>&emsp;&emsp;首先是cls_loss的计算，先将<code>labels</code>以及<code>label_weights</code> reshape成<code>[N, cls_num]</code>的形式（在focal loss中使用二分类损失，如果不用二分类损失每个anchor的label就是一个数字，就直接reshape成一个<code>[N]</code>的Tensor即可）；对于<code>cls_score</code>来说，它的shape是<code>[batch_size, num_cls, H, W]</code>，所以需要先交换维度后再reshape成<br><code>[N, cls_num]</code>的Tensor。接下来就是cls_criterion的选择，这部分不用解释，根据具体设置选择即可，在retinanet中选择的是<code>weighted_sigmoid_focal_loss</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> self.use_sigmoid_cls:</div><div class="line">    labels = labels.reshape(<span class="number">-1</span>, self.cls_out_channels)</div><div class="line">    label_weights = label_weights.reshape(<span class="number">-1</span>, self.cls_out_channels)</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    labels = labels.reshape(<span class="number">-1</span>)</div><div class="line">    label_weights = label_weights.reshape(<span class="number">-1</span>)</div><div class="line">cls_score = cls_score.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(</div><div class="line">    <span class="number">-1</span>, self.cls_out_channels)</div><div class="line"><span class="keyword">if</span> self.use_sigmoid_cls:</div><div class="line">    <span class="keyword">if</span> self.use_focal_loss:</div><div class="line">        cls_criterion = weighted_sigmoid_focal_loss</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        cls_criterion = weighted_binary_cross_entropy</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    <span class="keyword">if</span> self.use_focal_loss:</div><div class="line">        <span class="keyword">raise</span> NotImplementedError</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        cls_criterion = weighted_cross_entropy</div><div class="line"><span class="keyword">if</span> self.use_focal_loss:</div><div class="line">    loss_cls = cls_criterion(</div><div class="line">        cls_score,</div><div class="line">        labels,</div><div class="line">        label_weights,</div><div class="line">        gamma=cfg.gamma,</div><div class="line">        alpha=cfg.alpha,</div><div class="line">        avg_factor=num_total_samples)</div><div class="line"><span class="keyword">else</span>:</div><div class="line">    loss_cls = cls_criterion(</div><div class="line">        cls_score, labels, label_weights, avg_factor=num_total_samples)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;下面看一下focal loss的具体实现，其中涉及到<code>mmdet/core/loss/losses.py</code>中的<code>sigmoid_focal_loss()</code>和<code>weighted_sigmoid_focal_loss()</code>。主要计算其实在<code>sigmoid_focal_loss()</code>中。在看代码之前首先看一下focal loss的定义</p>
<script type="math/tex; mode=display">
\textbf{FL}(p_t)=-\alpha_t(1-p_t)^\gamma log(p_t)</script><p>&emsp;&emsp;其中$\alpha$和$\gamma$都属于超参，而$p_t$代表属于第t类的概率，而对于retinanet输出的每个channel在经过sigmoid后都代表属于该类别的概率，所以对于二分类的$p_t$和$\alpha_t$可以写作如下形式，设网络某个channel的输出为$p$，该类的label记作$t\in \{0,1\}$。</p>
<script type="math/tex; mode=display">
p_t=pt+(1-p)(1-t) \\
\alpha_t=p\alpha+(1-\alpha)(1-t)</script><p>代入focal loss的计算式，可以得到</p>
<script type="math/tex; mode=display">
\textbf{FL}(p_t)=-(p\alpha+(1-\alpha)(1-t))((1-p)t+p(1-t))^\gamma log(pt+(1-p)(1-t))</script><p>&emsp;&emsp;下面就可以利用这个计算式来计算focal loss，除去系数，其实剩下部分就是一个BCELoss，所以只有系数需要自己计算，而且不要忘记用系数与weight做element-wise product，将无效的anchor的loss置为0。代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_focal_loss</span><span class="params">(pred,</span></span></div><div class="line"><span class="function"><span class="params">                       target,</span></span></div><div class="line"><span class="function"><span class="params">                       weight,</span></span></div><div class="line"><span class="function"><span class="params">                       gamma=<span class="number">2.0</span>,</span></span></div><div class="line"><span class="function"><span class="params">                       alpha=<span class="number">0.25</span>,</span></span></div><div class="line"><span class="function"><span class="params">                       reduction=<span class="string">'mean'</span>)</span>:</span></div><div class="line">    pred_sigmoid = pred.sigmoid()</div><div class="line">    target = target.type_as(pred)</div><div class="line">    pt = (<span class="number">1</span> - pred_sigmoid) * target + pred_sigmoid * (<span class="number">1</span> - target)</div><div class="line">    weight = (alpha * target + (<span class="number">1</span> - alpha) * (<span class="number">1</span> - target)) * weight</div><div class="line">    weight = weight * pt.pow(gamma)</div><div class="line">    loss = F.binary_cross_entropy_with_logits(</div><div class="line">        pred, target, reduction=<span class="string">'none'</span>) * weight</div><div class="line">    reduction_enum = F._Reduction.get_enum(reduction)</div><div class="line">    <span class="comment"># none: 0, mean:1, sum: 2</span></div><div class="line">    <span class="keyword">if</span> reduction_enum == <span class="number">0</span>:</div><div class="line">        <span class="keyword">return</span> loss</div><div class="line">    <span class="keyword">elif</span> reduction_enum == <span class="number">1</span>:</div><div class="line">        <span class="keyword">return</span> loss.mean()</div><div class="line">    <span class="keyword">elif</span> reduction_enum == <span class="number">2</span>:</div><div class="line">        <span class="keyword">return</span> loss.sum()</div></pre></td></tr></table></figure>
<h5 id="②-回归损失"><a href="#②-回归损失" class="headerlink" title="② 回归损失"></a>② 回归损失</h5><p>&emsp;&emsp;下面是边框回归loss的计算，类似地，先对<code>bbox_targets</code>、<code>bbox_weights</code>和<code>bbox_pred</code>进行了reshape。随后调用<code>weighted_smoothl1()</code>进行计算。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">bbox_targets = bbox_targets.reshape(<span class="number">-1</span>, <span class="number">4</span>)</div><div class="line">bbox_weights = bbox_weights.reshape(<span class="number">-1</span>, <span class="number">4</span>)</div><div class="line">bbox_pred = bbox_pred.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(<span class="number">-1</span>, <span class="number">4</span>)</div><div class="line">loss_reg = weighted_smoothl1(</div><div class="line">    bbox_pred,</div><div class="line">    bbox_targets,</div><div class="line">    bbox_weights,</div><div class="line">    beta=cfg.smoothl1_beta,</div><div class="line">    avg_factor=num_total_samples)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;同样地，<code>weighted_smoothl1()</code>定义在<code>mmdet/core/loss/losses.py</code>中，这里面beta代表回归损失的系数，其余就是损失的计算。注意，在计算完loss后，同样要与<code>weight</code>做element-wise product，将非正样本的无用的loss清0。这里说一点题外话，这种给loss上加weight的做法非常像掩码，在mmdetection中weight都设置成与对应的Tensor相同的shape，例如bbox_target的shape是<code>[N, 4]</code>，weight的shape也是<code>[N, 4]</code>，并没有直接设置为<code>[N]</code>，这样十分清晰，要忽略不相关训练样本的loss直接做element-wise product就好。<code>weighted_smoothl1()</code>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weighted_smoothl1</span><span class="params">(pred, target, weight, beta=<span class="number">1.0</span>, avg_factor=None)</span>:</span></div><div class="line">    <span class="keyword">if</span> avg_factor <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        avg_factor = torch.sum(weight &gt; <span class="number">0</span>).float().item() / <span class="number">4</span> + <span class="number">1e-6</span></div><div class="line">    loss = smooth_l1_loss(pred, target, beta, reduction=<span class="string">'none'</span>)</div><div class="line">    <span class="keyword">return</span> torch.sum(loss * weight)[<span class="keyword">None</span>] / avg_factor</div></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/object-detection/" rel="tag"><i class="fa fa-tag"></i> object detection</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/03/26/anchor in object detection/" rel="next" title="物体检测中的anchor">
                <i class="fa fa-chevron-left"></i> 物体检测中的anchor
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://avatars2.githubusercontent.com/u/30823593?s=400&v=4"
               alt="ljm" />
          <p class="site-author-name" itemprop="name">ljm</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives">
            
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/mingming97" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、大体流程"><span class="nav-number">1.</span> <span class="nav-text">一、大体流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-训练逻辑"><span class="nav-number">1.1.</span> <span class="nav-text">1.  训练逻辑</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-技术细节"><span class="nav-number">1.2.</span> <span class="nav-text">2. 技术细节</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、网络结构"><span class="nav-number">2.</span> <span class="nav-text">二、网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-backbone"><span class="nav-number">2.1.</span> <span class="nav-text">1. backbone</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-neck"><span class="nav-number">2.2.</span> <span class="nav-text">2. neck</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-head"><span class="nav-number">2.3.</span> <span class="nav-text">3. head</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#（1）retinanet的head部分概述"><span class="nav-number">2.3.1.</span> <span class="nav-text">（1）retinanet的head部分概述</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（2）cls-scores以及bbox-preds的计算"><span class="nav-number">2.3.2.</span> <span class="nav-text">（2）cls_scores以及bbox_preds的计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（3）anchor的获得"><span class="nav-number">2.3.3.</span> <span class="nav-text">（3）anchor的获得</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（4）Anchor-target的获取"><span class="nav-number">2.3.4.</span> <span class="nav-text">（4）Anchor target的获取</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#①-anchor-target-mmdet-core-anchor-anchor-target-py"><span class="nav-number">2.3.4.1.</span> <span class="nav-text">① anchor_target (mmdet/core/anchor/anchor_target.py)</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#②-anchor-target-single-mmdet-core-anchor-anchor-target-py"><span class="nav-number">2.3.4.2.</span> <span class="nav-text">② anchor_target_single (mmdet/core/anchor/anchor_target.py)</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-loss的计算"><span class="nav-number">2.3.5.</span> <span class="nav-text">(5) loss的计算</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#①-分类损失"><span class="nav-number">2.3.5.1.</span> <span class="nav-text">① 分类损失</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#②-回归损失"><span class="nav-number">2.3.5.2.</span> <span class="nav-text">② 回归损失</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <!--<i class="fa fa-heart"></i> -->
    <i class="fa fa-cog" aria-hidden="true"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ljm</span>

  
</div>


  
  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_pv">
    访客数:<span id="busuanzi_value_site_pv">
  </div>

<!--
  <span class="post-meta-divider">|</span>

  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.2</div>
-->


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
