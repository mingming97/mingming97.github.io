<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="CV,Object Detection," />





  <link rel="alternate" href="/atom.xml" title="ljm's blog" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="http://ov718qcsg.bkt.clouddn.com/blog/icon/dove_128px_1154091_easyicon.net.ico?v=5.1.2" />






<meta name="description" content="&amp;emsp;&amp;emsp;本文阅读的版本是tensorflow对SSD的实现，相对而言阅读难度要远低于caffe版本的实现，源代码可见balancap/SSD-Tensorflow。 一、思路&amp;emsp;&amp;emsp;SSD的网络结构在论文中清晰可见，如图所示。具体是使用了VGG的基础结构，保留了前五层，将fc6和fc7改为了带孔卷积层，而且去掉了池化层和dropout，在不增加参数的条件下指数级扩大">
<meta name="keywords" content="CV,Object Detection">
<meta property="og:type" content="article">
<meta property="og:title" content="SSD源码阅读及原理详解">
<meta property="og:url" content="https://mingming97.github.io/2018/10/21/SSD/index.html">
<meta property="og:site_name" content="ljm&#39;s blog">
<meta property="og:description" content="&amp;emsp;&amp;emsp;本文阅读的版本是tensorflow对SSD的实现，相对而言阅读难度要远低于caffe版本的实现，源代码可见balancap/SSD-Tensorflow。 一、思路&amp;emsp;&amp;emsp;SSD的网络结构在论文中清晰可见，如图所示。具体是使用了VGG的基础结构，保留了前五层，将fc6和fc7改为了带孔卷积层，而且去掉了池化层和dropout，在不增加参数的条件下指数级扩大">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/structure.png">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/ssdstruct.jpg">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/extrafeature.jpg">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/defaultboxes1.jpg">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/defaultboxes2.jpg">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/defaultboxes3.jpg">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/total_loss.png">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/conf_loss.png">
<meta property="og:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/loc_loss.png">
<meta property="og:updated_time" content="2018-10-28T06:45:48.747Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SSD源码阅读及原理详解">
<meta name="twitter:description" content="&amp;emsp;&amp;emsp;本文阅读的版本是tensorflow对SSD的实现，相对而言阅读难度要远低于caffe版本的实现，源代码可见balancap/SSD-Tensorflow。 一、思路&amp;emsp;&amp;emsp;SSD的网络结构在论文中清晰可见，如图所示。具体是使用了VGG的基础结构，保留了前五层，将fc6和fc7改为了带孔卷积层，而且去掉了池化层和dropout，在不增加参数的条件下指数级扩大">
<meta name="twitter:image" content="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/structure.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://mingming97.github.io/2018/10/21/SSD/"/>





  <title>SSD源码阅读及原理详解 | ljm's blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript"
  color="0,0,255" opacity="0.3" zIndex="-1" count="30" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <a href="https://github.com/mingming97"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/a6677b08c955af8400f44c6298f40e7d19cc5b2d/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f677261795f3664366436642e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png"></a> 

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ljm's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://mingming97.github.io/2018/10/21/SSD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ljm">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="http://ov718qcsg.bkt.clouddn.com/blog/timg.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ljm's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">SSD源码阅读及原理详解</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-21T15:08:00+08:00">
                2018-10-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CV/" itemprop="url" rel="index">
                    <span itemprop="name">CV</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6,796
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  32
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>&emsp;&emsp;本文阅读的版本是tensorflow对SSD的实现，相对而言阅读难度要远低于caffe版本的实现，源代码可见<a href="https://github.com/balancap/SSD-Tensorflow/" target="_blank" rel="external">balancap/SSD-Tensorflow</a>。</p>
<h2 id="一、思路"><a href="#一、思路" class="headerlink" title="一、思路"></a>一、思路</h2><p>&emsp;&emsp;SSD的网络结构在论文中清晰可见，如图所示。具体是使用了VGG的基础结构，保留了前五层，将fc6和fc7改为了带孔卷积层，而且去掉了池化层和dropout，在不增加参数的条件下指数级扩大了感受野，而且没有因为池化导致丢失太多的信息；后面再额外增加了3个卷积层和一个average pooling层，目的是使用不同层的feature map来检测不同尺度的物体。之后从前面的卷积层中提取了conv4_3，从后面新增的卷积层中提取了conv7，conv8_2，conv9_2，conv10_2，conv11_2来作为检测使用的特征图，在这些不同尺度特征图上提取不同数目的default boxes，对其进行分类和边框回归得到物体框和类别，最后进行nms来进行筛选。简而言之，SSD预测的目标就是以一张图中的所有提取出的anchor boxes为窗口，检测其中是否有物体，如果有，预测它的类别并对其位置进行精修，没有物体则将其分类为背景。</p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/structure.png" alt=""></p>
<p>&emsp;&emsp;通俗一点的思路如下面的两个图所示，SSD所做的其实就是将feature map用额外的两个卷积层去卷积得到分类评分和边框回归的偏移，其中k表示从该层feature的每个anchor处提取的不同default boxes的个数，这些词具体是什么可以在后面的代码细节中看到。其他的一些细节，例如数据增广，mining hard examples等，也都在代码中有体现。</p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/ssdstruct.jpg" alt=""></p>
<p>下面是提取结果的卷积层的放大图。</p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/extrafeature.jpg" alt=""></p>
<p>&emsp;&emsp;每个feature map可以分两条路，分别得到分类结果和回归结果，再通过已有的ground truth box及其类别得到每个default box的分类和边框偏移，就可以计算loss，进行训练了。</p>
<h2 id="二、default-boxes提取"><a href="#二、default-boxes提取" class="headerlink" title="二、default boxes提取"></a>二、default boxes提取</h2><p>&emsp;&emsp;default boxes的选取与faster rcnn中的anchor有一些类似，就是按照不同的scale和ratio生成k个boxes，看下面的图就能大概了解其思想</p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/defaultboxes1.jpg" alt=""></p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/defaultboxes2.jpg" alt=""></p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/defaultboxes3.jpg" alt=""></p>
<ul>
<li><p>scale：scale指的是所检测的框的大小相对于原图的比例。比例低的可以框出图中的小物体，比例高的可以框出图中的大物体。深层次的feature map适合检测大物体，所以此处使用了一个线性关系来设置各个feature map所检测的scale。公式如下</p>
<script type="math/tex; mode=display">
s_k = s_{min} + \displaystyle\frac{s_{max}-s_{min}}{m-1}(k-1),k\in[1,m]</script><p>其中m是特征图的个数，实际取的时候为5，因为conv4_3层是单独设置的大小。$s_k$是第k个特征图的scale，$s_{min}$和$s_{max}$表示scale的最小值和最大值，在原论文中分别取0.2和0.9，而第一个特征图的scale一般设为$s_{min}$的一半，为0.1，所以对于300$\times$300的图片，最小的比例为300<em>0.1=30，之后每个对应feature map所检测的default boxes的大小都是300\</em>$s_k$。在caffe源码中的计算是先给出了$s_k$的增长步长，也就是$\displaystyle \lfloor\frac{\lfloor s_{max}\times100\rfloor-\lfloor s_{min}\times100\rfloor}{m-1}\rfloor=17$，由此可以得到5个值分别为20，37，54，71，88（后面还会得到另一个虚拟值是88+17=105）。这些比例乘图片大小再除以100，就能得到各个特征图的大小分别为60，111，162，213，264。再结合最小比例，可以得到default boxes的实际尺度分别为30，60，111，162，213，264。</p>
</li>
<li><p>aspect ratio：aspect ratio指的是default boxes的横纵比，一般有$\displaystyle a_r \in \{1,2,3,\frac{1}{2},\frac{1}{3}\}$，对于特定的横纵比，会使用</p>
<script type="math/tex; mode=display">
w_k^a=s_k\sqrt{a_r}\ \ \ \ \ \ h_k^a=\displaystyle\frac{s_k}{\sqrt{a_r}}</script><p>来计算真正的宽度和高度（此处$s_k$也是指真实的大小，也就是上文中的30，60，111，…）。默认情况下，每个特征图会有一个$a_r=1$的default box，除此之外还会设置一个$s_k^{\ ‘}=\sqrt{s_k s_{k+1}}$，$a_r=1$的default box，也就是说每个特征图中都会设置两个大小不同的正方形的default box，此处最后一个特征图就需要用到之前的虚拟值105（对应的实际尺度是315）。然而在实现时，使用的比例是可以自己选择的，理论上每个feature map都应该有6个default boxes，但是实际实现中某些层只使用了4个default box，没有使用长宽比为$3$和$\frac{1}{3}$的default box。</p>
</li>
<li><p>default box中心：default box的中心在计算的时候需要恢复为原图的相对坐标，所以每个中心设置为$\displaystyle\left(\frac{i+0.5}{|f_k|},\frac{j+0.5}{|f_k|}\right)\ \ i,j \in [0, |f_k|)$，其中$|f_k|$表示第k个feature map的大小。</p>
</li>
</ul>
<p>综上可以得到如下表格</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">feature map</th>
<th style="text-align:center">feature map size</th>
<th style="text-align:center">min_size($\textbf{s}_\textbf{k}$)</th>
<th style="text-align:center">max_size($\textbf{s}_\textbf{k+1}$)</th>
<th style="text-align:center">aspect_ratio</th>
<th style="text-align:center">step</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">conv4_3</td>
<td style="text-align:center">38$\times$38</td>
<td style="text-align:center">30</td>
<td style="text-align:center">60</td>
<td style="text-align:center">1,2,$\frac{1}{2}$</td>
<td style="text-align:center">8</td>
</tr>
<tr>
<td style="text-align:center">conv7</td>
<td style="text-align:center">19$\times$19</td>
<td style="text-align:center">60</td>
<td style="text-align:center">111</td>
<td style="text-align:center">1,2,3,$\frac{1}{2}$,$\frac{1}{3}$</td>
<td style="text-align:center">16</td>
</tr>
<tr>
<td style="text-align:center">conv8_2</td>
<td style="text-align:center">10$\times$10</td>
<td style="text-align:center">111</td>
<td style="text-align:center">162</td>
<td style="text-align:center">1,2,3,$\frac{1}{2}$,$\frac{1}{3}$</td>
<td style="text-align:center">32</td>
</tr>
<tr>
<td style="text-align:center">conv9_2</td>
<td style="text-align:center">5$\times$5</td>
<td style="text-align:center">162</td>
<td style="text-align:center">213</td>
<td style="text-align:center">1,2,3,$\frac{1}{2}$,$\frac{1}{3}$</td>
<td style="text-align:center">64</td>
</tr>
<tr>
<td style="text-align:center">conv10_2</td>
<td style="text-align:center">3$\times$3</td>
<td style="text-align:center">213</td>
<td style="text-align:center">264</td>
<td style="text-align:center">1,2,$\frac{1}{2}$</td>
<td style="text-align:center">100</td>
</tr>
<tr>
<td style="text-align:center">conv11_2</td>
<td style="text-align:center">1$\times$1</td>
<td style="text-align:center">264</td>
<td style="text-align:center">315</td>
<td style="text-align:center">1,2,$\frac{1}{2}$</td>
<td style="text-align:center">300</td>
</tr>
</tbody>
</table>
</div>
<p>以上所有的内容在源码中都是有对应的体现的，首先看关于default box的一些设置，代码在<code>ssd_vgg_300.py</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">default_params = SSDParams(</div><div class="line">    img_shape=(<span class="number">300</span>, <span class="number">300</span>),</div><div class="line">    num_classes=<span class="number">21</span>,</div><div class="line">    no_annotation_label=<span class="number">21</span>,</div><div class="line">    feat_layers=[<span class="string">'block4'</span>, <span class="string">'block7'</span>, <span class="string">'block8'</span>, <span class="string">'block9'</span>, <span class="string">'block10'</span>, <span class="string">'block11'</span>],</div><div class="line">    feat_shapes=[(<span class="number">38</span>, <span class="number">38</span>), (<span class="number">19</span>, <span class="number">19</span>), (<span class="number">10</span>, <span class="number">10</span>), (<span class="number">5</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">3</span>), (<span class="number">1</span>, <span class="number">1</span>)],</div><div class="line">    anchor_size_bounds=[<span class="number">0.15</span>, <span class="number">0.90</span>],</div><div class="line">    <span class="comment"># anchor_size_bounds=[0.20, 0.90],</span></div><div class="line">    anchor_sizes=[(<span class="number">21.</span>, <span class="number">45.</span>),</div><div class="line">                  (<span class="number">45.</span>, <span class="number">99.</span>),</div><div class="line">                  (<span class="number">99.</span>, <span class="number">153.</span>),</div><div class="line">                  (<span class="number">153.</span>, <span class="number">207.</span>),</div><div class="line">                  (<span class="number">207.</span>, <span class="number">261.</span>),</div><div class="line">                  (<span class="number">261.</span>, <span class="number">315.</span>)],</div><div class="line">    <span class="comment"># anchor_sizes=[(30., 60.),</span></div><div class="line">    <span class="comment">#               (60., 111.),</span></div><div class="line">    <span class="comment">#               (111., 162.),</span></div><div class="line">    <span class="comment">#               (162., 213.),</span></div><div class="line">    <span class="comment">#               (213., 264.),</span></div><div class="line">    <span class="comment">#               (264., 315.)],</span></div><div class="line">    anchor_ratios=[[<span class="number">2</span>, <span class="number">.5</span>],</div><div class="line">                   [<span class="number">2</span>, <span class="number">.5</span>, <span class="number">3</span>, <span class="number">1.</span>/<span class="number">3</span>],</div><div class="line">                   [<span class="number">2</span>, <span class="number">.5</span>, <span class="number">3</span>, <span class="number">1.</span>/<span class="number">3</span>],</div><div class="line">                   [<span class="number">2</span>, <span class="number">.5</span>, <span class="number">3</span>, <span class="number">1.</span>/<span class="number">3</span>],</div><div class="line">                   [<span class="number">2</span>, <span class="number">.5</span>],</div><div class="line">                   [<span class="number">2</span>, <span class="number">.5</span>]],</div><div class="line">    anchor_steps=[<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>, <span class="number">100</span>, <span class="number">300</span>],</div><div class="line">    anchor_offset=<span class="number">0.5</span>,</div><div class="line">    normalizations=[<span class="number">20</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>],</div><div class="line">    prior_scaling=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>]</div><div class="line">    )</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;其中img_shape代表输入图片的大小；num_classes代表输入的类别（20+1个背景类）；feat_layers代表提取的层；feat_shapes代表各个提取的featrue map的大小；anchor_size_bounds代表前文所说的$s_k$（原论文中取0.2到0.9）；anchor_sizes保存的是各层提取的default boxes的大小，也就是上面说的实际尺度；anchor_ratios是前面所说的各层的default boxes的横纵比；anchor_steps指的实际是default box的中心点坐标映射回原图的比例，做法就是用中心点坐标乘以对应的step；anchor_offset对应前文的offset；其余变量暂时与default boxes的生成无关。</p>
<p>&emsp;&emsp;整个训练过程都在<code>train_ssd_network.py</code>中，从这个文件中可以看出，第一步anchors的获取是通过<code>ssd_anchors = ssd_net.anchors(ssd_shape)</code>这句代码来获取的，而<code>ssd_net</code>这个对象是经由一个工厂类生成的一个网络类，此处以ssd_vgg_300为例，可以当作<code>ssd_net</code>就是一个<code>ssd_vgg_300.py</code>中定义的<code>SSDNet</code>的实例。这个被调用的函数可以在<code>ssd_vgg_300.py</code>中找到。而这个函数也只有一句话，那就是</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">return</span> ssd_anchors_all_layers(img_shape,</div><div class="line">                              self.params.feat_shapes,</div><div class="line">                              self.params.anchor_sizes,</div><div class="line">                              self.params.anchor_ratios,</div><div class="line">                              self.params.anchor_steps,</div><div class="line">                              self.params.anchor_offset,</div><div class="line">                              dtype)</div></pre></td></tr></table></figure>
<p><code>ssd_anchors_all_layers</code>在该文件中的后半部分定义，只有几句话：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ssd_anchors_all_layers</span><span class="params">(img_shape,</span></span></div><div class="line"><span class="function"><span class="params">                           layers_shape,</span></span></div><div class="line"><span class="function"><span class="params">                           anchor_sizes,</span></span></div><div class="line"><span class="function"><span class="params">                           anchor_ratios,</span></span></div><div class="line"><span class="function"><span class="params">                           anchor_steps,</span></span></div><div class="line"><span class="function"><span class="params">                           offset=<span class="number">0.5</span>,</span></span></div><div class="line"><span class="function"><span class="params">                           dtype=np.float32)</span>:</span></div><div class="line">    <span class="string">"""Compute anchor boxes for all feature layers.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    layers_anchors = []</div><div class="line">    <span class="keyword">for</span> i, s <span class="keyword">in</span> enumerate(layers_shape):</div><div class="line">        anchor_bboxes = ssd_anchor_one_layer(img_shape, s,</div><div class="line">                                             anchor_sizes[i],</div><div class="line">                                             anchor_ratios[i],</div><div class="line">                                             anchor_steps[i],</div><div class="line">                                             offset=offset, dtype=dtype)</div><div class="line">        layers_anchors.append(anchor_bboxes)</div><div class="line">    <span class="keyword">return</span> layers_anchors</div></pre></td></tr></table></figure>
<p>可以看出，它是一层一层获取default box，再添加到列表中，此处使用了获取一层default box的函数，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ssd_anchor_one_layer</span><span class="params">(img_shape,</span></span></div><div class="line"><span class="function"><span class="params">                         feat_shape,</span></span></div><div class="line"><span class="function"><span class="params">                         sizes,</span></span></div><div class="line"><span class="function"><span class="params">                         ratios,</span></span></div><div class="line"><span class="function"><span class="params">                         step,</span></span></div><div class="line"><span class="function"><span class="params">                         offset=<span class="number">0.5</span>,</span></span></div><div class="line"><span class="function"><span class="params">                         dtype=np.float32)</span>:</span></div><div class="line">    <span class="string">"""Computer SSD default anchor boxes for one feature layer.</span></div><div class="line"><span class="string">    Determine the relative position grid of the centers, and the relative</span></div><div class="line"><span class="string">    width and height.</span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">      feat_shape: Feature shape, used for computing relative position grids;</span></div><div class="line"><span class="string">      size: Absolute reference sizes;</span></div><div class="line"><span class="string">      ratios: Ratios to use on these features;</span></div><div class="line"><span class="string">      img_shape: Image shape, used for computing height, width relatively to the</span></div><div class="line"><span class="string">        former;</span></div><div class="line"><span class="string">      offset: Grid offset.</span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">      y, x, h, w: Relative x and y grids, and height and width.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="comment"># Compute the position grid: simple way.</span></div><div class="line">    <span class="comment"># y, x = np.mgrid[0:feat_shape[0], 0:feat_shape[1]]</span></div><div class="line">    <span class="comment"># y = (y.astype(dtype) + offset) / feat_shape[0]</span></div><div class="line">    <span class="comment"># x = (x.astype(dtype) + offset) / feat_shape[1]</span></div><div class="line">    <span class="comment"># Weird SSD-Caffe computation using steps values...</span></div><div class="line">    y, x = np.mgrid[<span class="number">0</span>:feat_shape[<span class="number">0</span>], <span class="number">0</span>:feat_shape[<span class="number">1</span>]]</div><div class="line">    y = (y.astype(dtype) + offset) * step / img_shape[<span class="number">0</span>]</div><div class="line">    x = (x.astype(dtype) + offset) * step / img_shape[<span class="number">1</span>]</div><div class="line">    <span class="comment"># Expand dims to support easy broadcasting.</span></div><div class="line">    y = np.expand_dims(y, axis=<span class="number">-1</span>)</div><div class="line">    x = np.expand_dims(x, axis=<span class="number">-1</span>)</div><div class="line">    <span class="comment"># Compute relative height and width.</span></div><div class="line">    <span class="comment"># Tries to follow the original implementation of SSD for the order.</span></div><div class="line">    num_anchors = len(sizes) + len(ratios)</div><div class="line">    h = np.zeros((num_anchors, ), dtype=dtype)</div><div class="line">    w = np.zeros((num_anchors, ), dtype=dtype)</div><div class="line">    <span class="comment"># Add first anchor boxes with ratio=1.</span></div><div class="line">    h[<span class="number">0</span>] = sizes[<span class="number">0</span>] / img_shape[<span class="number">0</span>]</div><div class="line">    w[<span class="number">0</span>] = sizes[<span class="number">0</span>] / img_shape[<span class="number">1</span>]</div><div class="line">    di = <span class="number">1</span></div><div class="line">    <span class="keyword">if</span> len(sizes) &gt; <span class="number">1</span>:</div><div class="line">        h[<span class="number">1</span>] = math.sqrt(sizes[<span class="number">0</span>] * sizes[<span class="number">1</span>]) / img_shape[<span class="number">0</span>]</div><div class="line">        w[<span class="number">1</span>] = math.sqrt(sizes[<span class="number">0</span>] * sizes[<span class="number">1</span>]) / img_shape[<span class="number">1</span>]</div><div class="line">        di += <span class="number">1</span></div><div class="line">    <span class="keyword">for</span> i, r <span class="keyword">in</span> enumerate(ratios):</div><div class="line">        h[i+di] = sizes[<span class="number">0</span>] / img_shape[<span class="number">0</span>] / math.sqrt(r)</div><div class="line">        w[i+di] = sizes[<span class="number">0</span>] / img_shape[<span class="number">1</span>] * math.sqrt(r)</div><div class="line">    <span class="keyword">return</span> y, x, h, w</div></pre></td></tr></table></figure>
<p>代码结合上面的讲解很好理解，通过上述的步骤，就得到了所有层的default box的y，x，h，w。举例来说，对于第一个特征图而言，y，x，h，w，的shape分别为(38,38,1)，(38,38,1)，(4, )，(4, )。</p>
<h2 id="三、Bboxes-Encode"><a href="#三、Bboxes-Encode" class="headerlink" title="三、Bboxes Encode"></a>三、Bboxes Encode</h2><p>&emsp;&emsp;要想理解这部分，需要知道什么是边框回归，此处有一个很好的讲解博客：<a href="https://blog.csdn.net/zijin0802034/article/details/77685438" target="_blank" rel="external"> 边框回归详解 </a>。知道了什么是边框回归，也就能理解我们这一步要干什么，主要有两个任务：1.给每个default box找到其对应的ground truth box，顺带得到其类别和得分。2.计算其相对于对应的ground truth box的变换，也就是边框回归要得到的目标变换。显然，这两步正是相当于给default boxes打上label的过程，对应之前说过的分类任务和回归任务。</p>
<p>&emsp;&emsp;在train的过程中只用一句话得到了每个default box的分类，边框偏移以及得分（用IOU定义，与GT box的IOU越大，得分越高），如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">gclasses, glocalisations, gscores = \</div><div class="line">    ssd_net.bboxes_encode(glabels, gbboxes, ssd_anchors)</div></pre></td></tr></table></figure>
<p>这个函数同样在<code>ssd_vgg_300.py</code>，源码是</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bboxes_encode</span><span class="params">(self, labels, bboxes, anchors,</span></span></div><div class="line"><span class="function"><span class="params">                  scope=None)</span>:</span></div><div class="line">    <span class="string">"""Encode labels and bounding boxes.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="keyword">return</span> ssd_common.tf_ssd_bboxes_encode(</div><div class="line">        labels, bboxes, anchors,</div><div class="line">        self.params.num_classes,</div><div class="line">        self.params.no_annotation_label,</div><div class="line">        ignore_threshold=<span class="number">0.5</span>,</div><div class="line">        prior_scaling=self.params.prior_scaling,</div><div class="line">        scope=scope)</div></pre></td></tr></table></figure>
<p>可以看出，结果是通过一个叫<code>tf_ssd_bboxes_encode</code>的函数获得的，其定义于<code>ssd_common.py</code>，如下所示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tf_ssd_bboxes_encode</span><span class="params">(labels,</span></span></div><div class="line"><span class="function"><span class="params">                         bboxes,</span></span></div><div class="line"><span class="function"><span class="params">                         anchors,</span></span></div><div class="line"><span class="function"><span class="params">                         num_classes,</span></span></div><div class="line"><span class="function"><span class="params">                         no_annotation_label,</span></span></div><div class="line"><span class="function"><span class="params">                         ignore_threshold=<span class="number">0.5</span>,</span></span></div><div class="line"><span class="function"><span class="params">                         prior_scaling=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],</span></span></div><div class="line"><span class="function"><span class="params">                         dtype=tf.float32,</span></span></div><div class="line"><span class="function"><span class="params">                         scope=<span class="string">'ssd_bboxes_encode'</span>)</span>:</span></div><div class="line">    <span class="string">"""Encode groundtruth labels and bounding boxes using SSD net anchors.</span></div><div class="line"><span class="string">    Encoding boxes for all feature layers.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">      labels: 1D Tensor(int64) containing groundtruth labels;</span></div><div class="line"><span class="string">      bboxes: Nx4 Tensor(float) with bboxes relative coordinates;</span></div><div class="line"><span class="string">      anchors: List of Numpy array with layer anchors;</span></div><div class="line"><span class="string">      matching_threshold: Threshold for positive match with groundtruth bboxes;</span></div><div class="line"><span class="string">      prior_scaling: Scaling of encoded coordinates.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">      (target_labels, target_localizations, target_scores):</span></div><div class="line"><span class="string">        Each element is a list of target Tensors.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="keyword">with</span> tf.name_scope(scope):</div><div class="line">        target_labels = []</div><div class="line">        target_localizations = []</div><div class="line">        target_scores = []</div><div class="line">        <span class="keyword">for</span> i, anchors_layer <span class="keyword">in</span> enumerate(anchors):</div><div class="line">            <span class="keyword">with</span> tf.name_scope(<span class="string">'bboxes_encode_block_%i'</span> % i):</div><div class="line">                t_labels, t_loc, t_scores = \</div><div class="line">                    tf_ssd_bboxes_encode_layer(labels, bboxes, anchors_layer,</div><div class="line">                                               num_classes, no_annotation_label,</div><div class="line">                                               ignore_threshold,</div><div class="line">                                               prior_scaling, dtype)</div><div class="line">                target_labels.append(t_labels)</div><div class="line">                target_localizations.append(t_loc)</div><div class="line">                target_scores.append(t_scores)</div><div class="line">        <span class="keyword">return</span> target_labels, target_localizations, target_scores</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;可以看出，类似于anchors的获得，default box的标定也是先一个特征图一个特征图进行，之后再将一个特征图的结果分别放入对应列表中。下面来看每个特征图是如何处理的，处理一个特征图的函数是<code>tf_ssd_bboxes_encode_layer</code>，源码见下面</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tf_ssd_bboxes_encode_layer</span><span class="params">(labels,</span></span></div><div class="line"><span class="function"><span class="params">                               bboxes,</span></span></div><div class="line"><span class="function"><span class="params">                               anchors_layer,</span></span></div><div class="line"><span class="function"><span class="params">                               num_classes,</span></span></div><div class="line"><span class="function"><span class="params">                               no_annotation_label,</span></span></div><div class="line"><span class="function"><span class="params">                               ignore_threshold=<span class="number">0.5</span>,</span></span></div><div class="line"><span class="function"><span class="params">                               prior_scaling=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>],</span></span></div><div class="line"><span class="function"><span class="params">                               dtype=tf.float32)</span>:</span></div><div class="line">    <span class="string">"""Encode groundtruth labels and bounding boxes using SSD anchors from</span></div><div class="line"><span class="string">    one layer.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">      labels: 1D Tensor(int64) containing groundtruth labels;</span></div><div class="line"><span class="string">      bboxes: Nx4 Tensor(float) with bboxes relative coordinates;</span></div><div class="line"><span class="string">      anchors_layer: Numpy array with layer anchors;</span></div><div class="line"><span class="string">      matching_threshold: Threshold for positive match with groundtruth bboxes;</span></div><div class="line"><span class="string">      prior_scaling: Scaling of encoded coordinates.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">      (target_labels, target_localizations, target_scores): Target Tensors.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="comment"># Anchors coordinates and volume.</span></div><div class="line">    yref, xref, href, wref = anchors_layer</div><div class="line">    ymin = yref - href / <span class="number">2.</span></div><div class="line">    xmin = xref - wref / <span class="number">2.</span></div><div class="line">    ymax = yref + href / <span class="number">2.</span></div><div class="line">    xmax = xref + wref / <span class="number">2.</span></div><div class="line">    vol_anchors = (xmax - xmin) * (ymax - ymin)</div><div class="line"></div><div class="line">    <span class="comment"># Initialize tensors...</span></div><div class="line">    shape = (yref.shape[<span class="number">0</span>], yref.shape[<span class="number">1</span>], href.size)</div><div class="line">    feat_labels = tf.zeros(shape, dtype=tf.int64)</div><div class="line">    feat_scores = tf.zeros(shape, dtype=dtype)</div><div class="line"></div><div class="line">    feat_ymin = tf.zeros(shape, dtype=dtype)</div><div class="line">    feat_xmin = tf.zeros(shape, dtype=dtype)</div><div class="line">    feat_ymax = tf.ones(shape, dtype=dtype)</div><div class="line">    feat_xmax = tf.ones(shape, dtype=dtype)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">jaccard_with_anchors</span><span class="params">(bbox)</span>:</span></div><div class="line">        <span class="string">"""Compute jaccard score between a box and the anchors.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        int_ymin = tf.maximum(ymin, bbox[<span class="number">0</span>])</div><div class="line">        int_xmin = tf.maximum(xmin, bbox[<span class="number">1</span>])</div><div class="line">        int_ymax = tf.minimum(ymax, bbox[<span class="number">2</span>])</div><div class="line">        int_xmax = tf.minimum(xmax, bbox[<span class="number">3</span>])</div><div class="line">        h = tf.maximum(int_ymax - int_ymin, <span class="number">0.</span>)</div><div class="line">        w = tf.maximum(int_xmax - int_xmin, <span class="number">0.</span>)</div><div class="line">        <span class="comment"># Volumes.</span></div><div class="line">        inter_vol = h * w</div><div class="line">        union_vol = vol_anchors - inter_vol \</div><div class="line">            + (bbox[<span class="number">2</span>] - bbox[<span class="number">0</span>]) * (bbox[<span class="number">3</span>] - bbox[<span class="number">1</span>])</div><div class="line">        jaccard = tf.div(inter_vol, union_vol)</div><div class="line">        <span class="keyword">return</span> jaccard</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">intersection_with_anchors</span><span class="params">(bbox)</span>:</span></div><div class="line">        <span class="string">"""Compute intersection between score a box and the anchors.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        int_ymin = tf.maximum(ymin, bbox[<span class="number">0</span>])</div><div class="line">        int_xmin = tf.maximum(xmin, bbox[<span class="number">1</span>])</div><div class="line">        int_ymax = tf.minimum(ymax, bbox[<span class="number">2</span>])</div><div class="line">        int_xmax = tf.minimum(xmax, bbox[<span class="number">3</span>])</div><div class="line">        h = tf.maximum(int_ymax - int_ymin, <span class="number">0.</span>)</div><div class="line">        w = tf.maximum(int_xmax - int_xmin, <span class="number">0.</span>)</div><div class="line">        inter_vol = h * w</div><div class="line">        scores = tf.div(inter_vol, vol_anchors)</div><div class="line">        <span class="keyword">return</span> scores</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">condition</span><span class="params">(i, feat_labels, feat_scores,</span></span></div><div class="line"><span class="function"><span class="params">                  feat_ymin, feat_xmin, feat_ymax, feat_xmax)</span>:</span></div><div class="line">        <span class="string">"""Condition: check label index.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        r = tf.less(i, tf.shape(labels))</div><div class="line">        <span class="keyword">return</span> r[<span class="number">0</span>]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">body</span><span class="params">(i, feat_labels, feat_scores,</span></span></div><div class="line"><span class="function"><span class="params">             feat_ymin, feat_xmin, feat_ymax, feat_xmax)</span>:</span></div><div class="line">        <span class="string">"""Body: update feature labels, scores and bboxes.</span></div><div class="line"><span class="string">        Follow the original SSD paper for that purpose:</span></div><div class="line"><span class="string">          - assign values when jaccard &gt; 0.5;</span></div><div class="line"><span class="string">          - only update if beat the score of other bboxes.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="comment"># Jaccard score.</span></div><div class="line">        label = labels[i]</div><div class="line">        bbox = bboxes[i]</div><div class="line">        jaccard = jaccard_with_anchors(bbox)</div><div class="line">        <span class="comment"># Mask: check threshold + scores + no annotations + num_classes.</span></div><div class="line">        mask = tf.greater(jaccard, feat_scores)</div><div class="line">        <span class="comment"># mask = tf.logical_and(mask, tf.greater(jaccard, matching_threshold))</span></div><div class="line">        mask = tf.logical_and(mask, feat_scores &gt; <span class="number">-0.5</span>)</div><div class="line">        mask = tf.logical_and(mask, label &lt; num_classes)</div><div class="line">        imask = tf.cast(mask, tf.int64)</div><div class="line">        fmask = tf.cast(mask, dtype)</div><div class="line">        <span class="comment"># Update values using mask.</span></div><div class="line">        feat_labels = imask * label + (<span class="number">1</span> - imask) * feat_labels</div><div class="line">        feat_scores = tf.where(mask, jaccard, feat_scores)</div><div class="line"></div><div class="line">        feat_ymin = fmask * bbox[<span class="number">0</span>] + (<span class="number">1</span> - fmask) * feat_ymin</div><div class="line">        feat_xmin = fmask * bbox[<span class="number">1</span>] + (<span class="number">1</span> - fmask) * feat_xmin</div><div class="line">        feat_ymax = fmask * bbox[<span class="number">2</span>] + (<span class="number">1</span> - fmask) * feat_ymax</div><div class="line">        feat_xmax = fmask * bbox[<span class="number">3</span>] + (<span class="number">1</span> - fmask) * feat_xmax</div><div class="line"></div><div class="line">        <span class="comment"># Check no annotation label: ignore these anchors...</span></div><div class="line">        <span class="comment"># interscts = intersection_with_anchors(bbox)</span></div><div class="line">        <span class="comment"># mask = tf.logical_and(interscts &gt; ignore_threshold,</span></div><div class="line">        <span class="comment">#                       label == no_annotation_label)</span></div><div class="line">        <span class="comment"># # Replace scores by -1.</span></div><div class="line">        <span class="comment"># feat_scores = tf.where(mask, -tf.cast(mask, dtype), feat_scores)</span></div><div class="line"></div><div class="line">        <span class="keyword">return</span> [i+<span class="number">1</span>, feat_labels, feat_scores,</div><div class="line">                feat_ymin, feat_xmin, feat_ymax, feat_xmax]</div><div class="line">    <span class="comment"># Main loop definition.</span></div><div class="line">    i = <span class="number">0</span></div><div class="line">    [i, feat_labels, feat_scores,</div><div class="line">     feat_ymin, feat_xmin,</div><div class="line">     feat_ymax, feat_xmax] = tf.while_loop(condition, body,</div><div class="line">                                           [i, feat_labels, feat_scores,</div><div class="line">                                            feat_ymin, feat_xmin,</div><div class="line">                                            feat_ymax, feat_xmax])</div><div class="line">    <span class="comment"># Transform to center / size.</span></div><div class="line">    feat_cy = (feat_ymax + feat_ymin) / <span class="number">2.</span></div><div class="line">    feat_cx = (feat_xmax + feat_xmin) / <span class="number">2.</span></div><div class="line">    feat_h = feat_ymax - feat_ymin</div><div class="line">    feat_w = feat_xmax - feat_xmin</div><div class="line">    <span class="comment"># Encode features.</span></div><div class="line">    feat_cy = (feat_cy - yref) / href / prior_scaling[<span class="number">0</span>]</div><div class="line">    feat_cx = (feat_cx - xref) / wref / prior_scaling[<span class="number">1</span>]</div><div class="line">    feat_h = tf.log(feat_h / href) / prior_scaling[<span class="number">2</span>]</div><div class="line">    feat_w = tf.log(feat_w / wref) / prior_scaling[<span class="number">3</span>]</div><div class="line">    <span class="comment"># Use SSD ordering: x / y / w / h instead of ours.</span></div><div class="line">    feat_localizations = tf.stack([feat_cx, feat_cy, feat_w, feat_h], axis=<span class="number">-1</span>)</div><div class="line">    <span class="keyword">return</span> feat_labels, feat_localizations, feat_scores</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;这个函数比较长，先看第一个函数之前的部分，首先是通过之前得到的一层特征图的y，x，h，w，计算每个default box的四个角的坐标及面积（此处利用了numpy的广播机制），随后初始化了一些空的tensor：类别标签、得分以及每个default box对应的GT box的四个角的坐标。shape也都符合之前的定义，此处以第一个特征图为例，其大小为38$\times$38，每个中心点对应4个default box，每个default box对应一个label，一个GT box和一个得分，所以所有初始化tensor的shape都是(38,38,4)。</p>
<p>&emsp;&emsp;下面是几个辅助函数，<code>jaccard_with_anchors(bbox)</code>用于计算bbox与所有default box的IOU；<code>intersection_with_anchors(bbox)</code>用于计算bbox与所有default box的交比上default box的面积的值，在此处没有用到这个函数；<code>condition</code>，<code>body</code>要和下面的<code>tf.while_loop</code>连起来看，<code>tf.while_loop</code>的执行逻辑是，若condition为真，执行body，<code>condition</code>只有一句话，其实就是判断<code>i</code>的值是否小于GT box的数目，也就是说整个循环逻辑是以每个GT box为单位进行的，<code>body</code>就是对每个GT box进行的操作。</p>
<p>&emsp;&emsp;在看<code>body</code>具体做了什么之前，需要先了解SSD中GT box的匹配机制。共有两个原则，第一个原则是每个GT box与其IOU最大的defaut box匹配，这样就能保证每个GT box都有一个与其匹配的default box。但是这样的话正负样本严重不平衡，因此还需要第二个原则，那就是对于未匹配的default box，若与某个GT box的IOU大于一个阈值（SSD中取0.5），那么也将其进行匹配，此处有一个问题就是若某个default box与几个GT box的IOU都大于阈值，选哪个与其匹配？显然，选与其IOU最大的那个GT box与之匹配。这样就大大增加了正样本的个数。还会有一个矛盾在于，假如一个GT box 1与其IOU最大的default box小于阈值，而该default box与某一个GT box 2的IOU大于阈值，如何选择。此处应该按照第一个原则，选择GT box 1，因为必须要保证每个GT box要有一个default box与之匹配。（实际情况中该矛盾发生可能较低，所以该tensorflow实现中仅实施了第二个原则。）</p>
<p>&emsp;&emsp;下面可以看一下<code>body</code>函数，可以看出，它的逻辑是使用某个GT box与所有default box的已经匹配的GT box的结果去比较，再决定是否更换每个default box对应的GT box。函数中出现了很多mask*A + (1-mask)*B的模式，mask的值只有0和1两种，那么这句话的意义就很显然了，如果mask为1，新值为A，否则为B，对应到具体情况中就是mask为1则更换对应GT box，为0则保持不变，那么决定是否更换的mask的值则来自于前面的条件判断，条件判断如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Mask: check threshold + scores + no annotations + num_classes.</span></div><div class="line">mask = tf.greater(jaccard, feat_scores)</div><div class="line"><span class="comment"># mask = tf.logical_and(mask, tf.greater(jaccard, matching_threshold))</span></div><div class="line">mask = tf.logical_and(mask, feat_scores &gt; <span class="number">-0.5</span>)</div><div class="line">mask = tf.logical_and(mask, label &lt; num_classes)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;此处更改了之前的逻辑，将大于阈值的部分去掉，改为只要大于之前的IOU，就进行GT box的匹配。</p>
<p>&emsp;&emsp;找到了所有default box对应的GT box的四个角的坐标，就可以开始进行边框偏移的计算，在SSD中此处有一个技巧，假设已知default box的位置$\boldsymbol{d=(d^{cx},d^{cy},d^w,d^h)}$，以及它对应的GT box的位置$\boldsymbol{b=(b^{cx},b^{cy},b^w,b^h)}$，通常的边框偏移是按照如下方式计算的</p>
<script type="math/tex; mode=display">
\begin{align}
& t^{cx} = \displaystyle\frac{b^{cx}-d^{cx}}{d^w} \\
& t^{cy} = \displaystyle\frac{b^{cy}-d^{cy}}{d^h} \\
& t^w = \displaystyle log\left(\frac{b^w}{d^w}\right) \\
& t^h = \displaystyle log\left(\frac{b^h}{d^h}\right) \\
\end{align}</script><p>&emsp;&emsp;这个过程称为编码（encode），对应的解码（decode）过程则为</p>
<script type="math/tex; mode=display">
\begin{align}
& b^{cx} = d^wt^{cx} + d^{cx} \\
& b^{cy} = d^ht^{cy} + d^{cy} \\
& b^w = d^wexp(t^w) \\
& b^h = d^hexp(t^h) \\
\end{align}</script><p>&emsp;&emsp;但是在SSD中设置了variance来调整对t的放缩，无论在解码还是编码时都会使用variance来控制，此时编码过程计算如下</p>
<script type="math/tex; mode=display">
\begin{align}
& t^{cx} = \displaystyle\frac{b^{cx}-d^{cx}}{d^w\times variance[0]} \\
& t^{cy} = \displaystyle\frac{b^{cy}-d^{cy}}{d^h\times variance[1]} \\
& t^w = \displaystyle \frac{log\left(\frac{b^w}{d^w}\right)}{variance[2]} \\
& t^h = \displaystyle \frac{log\left(\frac{b^h}{d^h}\right)}{variance[3]} \\
\end{align}</script><p>&emsp;&emsp;解码过程如下</p>
<script type="math/tex; mode=display">
\begin{align}
& b^{cx} = d^w(t^{cx}variance[0]) + d^{cx} \\
& b^{cy} = d^h(t^{cy}variance[1]) + d^{cy} \\
& b^w = d^wexp(t^wvariance[2]) \\
& b^h = d^hexp(t^hvariance[3]) \\
\end{align}</script><p>&emsp;&emsp;variance可以选择训练得到还是手动设定，在SSD中选择手动设定，这也就是<code>SSDParams</code>中<code>parior_scaling</code>中四个数的含义，其实就是对应的variance。</p>
<h2 id="四、网络结构"><a href="#四、网络结构" class="headerlink" title="四、网络结构"></a>四、网络结构</h2><p>&emsp;&emsp;除了对数据的预处理，以及并行化处理意外，接下来就是将数据喂进网络，得到每个default box的分类结果和边框偏移。接着看<code>train_ssd_network.py</code>，可以看到这样一句代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">predictions, localisations, logits, end_points = \</div><div class="line">    ssd_net.net(b_image, is_training=<span class="keyword">True</span>)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;它调用了net函数，返回了四个变量，为了清楚这个函数做了什么，提前说明四个变量的含义：<code>predictions</code>就是default box在各个类上的得分，也就是后面的<code>logits</code>通过softmax得到的结果，这样<code>logits</code>是什么就无需解释了，<code>localisations</code>是对default box的边框偏移预测结果，<code>end_points</code>是一个字典，里面储存着各个block的输出特征图。</p>
<p>&emsp;&emsp;下面来看net函数，发现它的核心只有一句话</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">r = ssd_net(inputs,</div><div class="line">            num_classes=self.params.num_classes,</div><div class="line">            feat_layers=self.params.feat_layers,</div><div class="line">            anchor_sizes=self.params.anchor_sizes,</div><div class="line">            anchor_ratios=self.params.anchor_ratios,</div><div class="line">            normalizations=self.params.normalizations,</div><div class="line">            is_training=is_training,</div><div class="line">            dropout_keep_prob=dropout_keep_prob,</div><div class="line">            prediction_fn=prediction_fn,</div><div class="line">            reuse=reuse,</div><div class="line">            scope=scope)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;而ssd_net是定义在跟net相同文件（<code>ssd_vgg_300.py</code>）中的一个函数，我们可以在下面找到它的代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ssd_net</span><span class="params">(inputs,</span></span></div><div class="line"><span class="function"><span class="params">            num_classes=SSDNet.default_params.num_classes,</span></span></div><div class="line"><span class="function"><span class="params">            feat_layers=SSDNet.default_params.feat_layers,</span></span></div><div class="line"><span class="function"><span class="params">            anchor_sizes=SSDNet.default_params.anchor_sizes,</span></span></div><div class="line"><span class="function"><span class="params">            anchor_ratios=SSDNet.default_params.anchor_ratios,</span></span></div><div class="line"><span class="function"><span class="params">            normalizations=SSDNet.default_params.normalizations,</span></span></div><div class="line"><span class="function"><span class="params">            is_training=True,</span></span></div><div class="line"><span class="function"><span class="params">            dropout_keep_prob=<span class="number">0.5</span>,</span></span></div><div class="line"><span class="function"><span class="params">            prediction_fn=slim.softmax,</span></span></div><div class="line"><span class="function"><span class="params">            reuse=None,</span></span></div><div class="line"><span class="function"><span class="params">            scope=<span class="string">'ssd_300_vgg'</span>)</span>:</span></div><div class="line">    <span class="string">"""SSD net definition.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="comment"># if data_format == 'NCHW':</span></div><div class="line">    <span class="comment">#     inputs = tf.transpose(inputs, perm=(0, 3, 1, 2))</span></div><div class="line"></div><div class="line">    <span class="comment"># End_points collect relevant activations for external use.</span></div><div class="line">    end_points = &#123;&#125;</div><div class="line">    <span class="keyword">with</span> tf.variable_scope(scope, <span class="string">'ssd_300_vgg'</span>, [inputs], reuse=reuse):</div><div class="line">        <span class="comment"># Original VGG-16 blocks.</span></div><div class="line">        net = slim.repeat(inputs, <span class="number">2</span>, slim.conv2d, <span class="number">64</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv1'</span>)</div><div class="line">        end_points[<span class="string">'block1'</span>] = net</div><div class="line">        net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">'pool1'</span>)</div><div class="line">        <span class="comment"># Block 2.</span></div><div class="line">        net = slim.repeat(net, <span class="number">2</span>, slim.conv2d, <span class="number">128</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv2'</span>)</div><div class="line">        end_points[<span class="string">'block2'</span>] = net</div><div class="line">        net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">'pool2'</span>)</div><div class="line">        <span class="comment"># Block 3.</span></div><div class="line">        net = slim.repeat(net, <span class="number">3</span>, slim.conv2d, <span class="number">256</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv3'</span>)</div><div class="line">        end_points[<span class="string">'block3'</span>] = net</div><div class="line">        net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">'pool3'</span>)</div><div class="line">        <span class="comment"># Block 4.</span></div><div class="line">        net = slim.repeat(net, <span class="number">3</span>, slim.conv2d, <span class="number">512</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv4'</span>)</div><div class="line">        end_points[<span class="string">'block4'</span>] = net</div><div class="line">        net = slim.max_pool2d(net, [<span class="number">2</span>, <span class="number">2</span>], scope=<span class="string">'pool4'</span>)</div><div class="line">        <span class="comment"># Block 5.</span></div><div class="line">        net = slim.repeat(net, <span class="number">3</span>, slim.conv2d, <span class="number">512</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv5'</span>)</div><div class="line">        end_points[<span class="string">'block5'</span>] = net</div><div class="line">        net = slim.max_pool2d(net, [<span class="number">3</span>, <span class="number">3</span>], stride=<span class="number">1</span>, scope=<span class="string">'pool5'</span>)</div><div class="line"></div><div class="line">        <span class="comment"># Additional SSD blocks.</span></div><div class="line">        <span class="comment"># Block 6: let's dilate the hell out of it!</span></div><div class="line">        net = slim.conv2d(net, <span class="number">1024</span>, [<span class="number">3</span>, <span class="number">3</span>], rate=<span class="number">6</span>, scope=<span class="string">'conv6'</span>)</div><div class="line">        end_points[<span class="string">'block6'</span>] = net</div><div class="line">        net = tf.layers.dropout(net, rate=dropout_keep_prob, training=is_training)</div><div class="line">        <span class="comment"># Block 7: 1x1 conv. Because the fuck.</span></div><div class="line">        net = slim.conv2d(net, <span class="number">1024</span>, [<span class="number">1</span>, <span class="number">1</span>], scope=<span class="string">'conv7'</span>)</div><div class="line">        end_points[<span class="string">'block7'</span>] = net</div><div class="line">        net = tf.layers.dropout(net, rate=dropout_keep_prob, training=is_training)</div><div class="line"></div><div class="line">        <span class="comment"># Block 8/9/10/11: 1x1 and 3x3 convolutions stride 2 (except lasts).</span></div><div class="line">        end_point = <span class="string">'block8'</span></div><div class="line">        <span class="keyword">with</span> tf.variable_scope(end_point):</div><div class="line">            net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">1</span>, <span class="number">1</span>], scope=<span class="string">'conv1x1'</span>)</div><div class="line">            net = custom_layers.pad2d(net, pad=(<span class="number">1</span>, <span class="number">1</span>))</div><div class="line">            net = slim.conv2d(net, <span class="number">512</span>, [<span class="number">3</span>, <span class="number">3</span>], stride=<span class="number">2</span>, scope=<span class="string">'conv3x3'</span>, padding=<span class="string">'VALID'</span>)</div><div class="line">        end_points[end_point] = net</div><div class="line">        end_point = <span class="string">'block9'</span></div><div class="line">        <span class="keyword">with</span> tf.variable_scope(end_point):</div><div class="line">            net = slim.conv2d(net, <span class="number">128</span>, [<span class="number">1</span>, <span class="number">1</span>], scope=<span class="string">'conv1x1'</span>)</div><div class="line">            net = custom_layers.pad2d(net, pad=(<span class="number">1</span>, <span class="number">1</span>))</div><div class="line">            net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">3</span>, <span class="number">3</span>], stride=<span class="number">2</span>, scope=<span class="string">'conv3x3'</span>, padding=<span class="string">'VALID'</span>)</div><div class="line">        end_points[end_point] = net</div><div class="line">        end_point = <span class="string">'block10'</span></div><div class="line">        <span class="keyword">with</span> tf.variable_scope(end_point):</div><div class="line">            net = slim.conv2d(net, <span class="number">128</span>, [<span class="number">1</span>, <span class="number">1</span>], scope=<span class="string">'conv1x1'</span>)</div><div class="line">            net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv3x3'</span>, padding=<span class="string">'VALID'</span>)</div><div class="line">        end_points[end_point] = net</div><div class="line">        end_point = <span class="string">'block11'</span></div><div class="line">        <span class="keyword">with</span> tf.variable_scope(end_point):</div><div class="line">            net = slim.conv2d(net, <span class="number">128</span>, [<span class="number">1</span>, <span class="number">1</span>], scope=<span class="string">'conv1x1'</span>)</div><div class="line">            net = slim.conv2d(net, <span class="number">256</span>, [<span class="number">3</span>, <span class="number">3</span>], scope=<span class="string">'conv3x3'</span>, padding=<span class="string">'VALID'</span>)</div><div class="line">        end_points[end_point] = net</div><div class="line"></div><div class="line">        <span class="comment"># Prediction and localisations layers.</span></div><div class="line">        predictions = []</div><div class="line">        logits = []</div><div class="line">        localisations = []</div><div class="line">        <span class="keyword">for</span> i, layer <span class="keyword">in</span> enumerate(feat_layers):</div><div class="line">            <span class="keyword">with</span> tf.variable_scope(layer + <span class="string">'_box'</span>):</div><div class="line">                p, l = ssd_multibox_layer(end_points[layer],</div><div class="line">                                          num_classes,</div><div class="line">                                          anchor_sizes[i],</div><div class="line">                                          anchor_ratios[i],</div><div class="line">                                          normalizations[i])</div><div class="line">            predictions.append(prediction_fn(p))</div><div class="line">            logits.append(p)</div><div class="line">            localisations.append(l)</div><div class="line"></div><div class="line">        <span class="keyword">return</span> predictions, localisations, logits, end_points</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;代码结构十分清晰，首先看前面定义网络的部分，这个定网络的定义与VGG16类似，只不过替换了其中某些层，原因在第一部分可以看到，可以看到在这一部分中每个block的输出被放进了<code>end_points</code>字典中。而后面则是根据特征图生成分类结果和偏移结果的部分，可以看到也是逐层进行并放到一个列表中的形式，每一层预测结果的获得都调用了<code>ssd_multibox_layer</code>函数，下面就看一下该函数的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ssd_multibox_layer</span><span class="params">(inputs,</span></span></div><div class="line"><span class="function"><span class="params">                       num_classes,</span></span></div><div class="line"><span class="function"><span class="params">                       sizes,</span></span></div><div class="line"><span class="function"><span class="params">                       ratios=[<span class="number">1</span>],</span></span></div><div class="line"><span class="function"><span class="params">                       normalization=<span class="number">-1</span>,</span></span></div><div class="line"><span class="function"><span class="params">                       bn_normalization=False)</span>:</span></div><div class="line">    <span class="string">"""Construct a multibox layer, return a class and localization predictions.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    net = inputs</div><div class="line">    <span class="keyword">if</span> normalization &gt; <span class="number">0</span>:</div><div class="line">        net = custom_layers.l2_normalization(net, scaling=<span class="keyword">True</span>)</div><div class="line">    <span class="comment"># Number of anchors.</span></div><div class="line">    num_anchors = len(sizes) + len(ratios)</div><div class="line"></div><div class="line">    <span class="comment"># Location.</span></div><div class="line">    num_loc_pred = num_anchors * <span class="number">4</span></div><div class="line">    loc_pred = slim.conv2d(net, num_loc_pred, [<span class="number">3</span>, <span class="number">3</span>], activation_fn=<span class="keyword">None</span>,</div><div class="line">                           scope=<span class="string">'conv_loc'</span>)</div><div class="line">    loc_pred = custom_layers.channel_to_last(loc_pred)</div><div class="line">    loc_pred = tf.reshape(loc_pred,</div><div class="line">                          tensor_shape(loc_pred, <span class="number">4</span>)[:<span class="number">-1</span>]+[num_anchors, <span class="number">4</span>])</div><div class="line">    <span class="comment"># Class prediction.</span></div><div class="line">    num_cls_pred = num_anchors * num_classes</div><div class="line">    cls_pred = slim.conv2d(net, num_cls_pred, [<span class="number">3</span>, <span class="number">3</span>], activation_fn=<span class="keyword">None</span>,</div><div class="line">                           scope=<span class="string">'conv_cls'</span>)</div><div class="line">    cls_pred = custom_layers.channel_to_last(cls_pred)</div><div class="line">    cls_pred = tf.reshape(cls_pred,</div><div class="line">                          tensor_shape(cls_pred, <span class="number">4</span>)[:<span class="number">-1</span>]+[num_anchors, num_classes])</div><div class="line">    <span class="keyword">return</span> cls_pred, loc_pred</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;<code>ssd_multibox_layer</code>同样定义于<code>ssd_vgg_300.py</code>中，可以看到一开始对normalization值进行了判断，此处就是<code>SSDParams</code>中<code>normalizations</code>的作用，在SSD中由于第一个要提取特征层较浅，其norm较大，所以要对其进行沿channel方向的l2_normalize，而其他层无需进行此操作，代码中也仅是判断了<code>normalization</code>的值是否大于0，所以在<code>normalizations</code>中第一个值大于0，其他都小于0，20和-1无实际含义。</p>
<p>&emsp;&emsp;下面则是对location的计算，首先使用了一个3*3卷积，通道数是每个中心default box的个数乘4，代表y，x，w，h四个偏移，从而得到了每个中心的边框偏移的结果，此处又进行了一个reshape操作，其中<code>tensor_shape</code>得到<code>loc_pred</code>的形状，再通过切片将最后一维去掉，再加上两维，分别是每个中心default box的个数，和4，这样就得到了[batch_size,size[0],size[1],num_anchors,4]的tensor。以第二个特征层为例，<code>loc_pred</code>的形状为[batch_size,19,19,6,4]，同理可以得到第二个特征层的<code>cls_pred</code>的形状为[batch_size,19,19,6,21]。</p>
<h2 id="五、loss的计算"><a href="#五、loss的计算" class="headerlink" title="五、loss的计算"></a>五、loss的计算</h2><p>&emsp;&emsp;SSD的loss是一个multitask的loss，包含分类损失和定位损失，公式如下所示</p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/total_loss.png" alt=""></p>
<p>&emsp;&emsp;所有此处所有的loss值均是对一张图而言的，式子中的$N$代表所有default box中正样本（有对应GT box）的数量，$\alpha$用于调整分类损失和定位损失的比例，下面看一下二者的具体计算。</p>
<p>&emsp;&emsp;首先看分类损失</p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/conf_loss.png" alt=""></p>
<p>&emsp;&emsp;式子中的$x_{ij}^p\in \{0,1\}$，类似于一个指示函数，当第i个default box与第j个GT box匹配并属于第p类时，$x_{ij}^p=1$，其他情况下$x_{ij}^p=0$。显然$c_i^p$就是之前得到的<code>logits</code>，所以整个式子其实就是一个交叉熵损失。</p>
<p>​    接下来看一下定位损失。</p>
<p><img src="http://ov718qcsg.bkt.clouddn.com/blog/ssdtensorflow/loc_loss.png" alt=""></p>
<p>&emsp;&emsp;定位损失中的$x_{ij}^p$与分类损失中的含义相同，$\hat g_j^m$根据下面的定义，含义是default box到其对应GT box的偏移，$l_i^m$则是预测的偏移，对二者的误差使用了smooth L1 loss。</p>
<p>&emsp;&emsp;与之前的过程类似，可以在<code>train_ssd_network.py</code>中看到求loss的代码，如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ssd_net.losses(logits, localisations,</div><div class="line">               b_gclasses, b_glocalisations, b_gscores,</div><div class="line">               match_threshold=FLAGS.match_threshold,</div><div class="line">               negative_ratio=FLAGS.negative_ratio,</div><div class="line">               alpha=FLAGS.loss_alpha,</div><div class="line">               label_smoothing=FLAGS.label_smoothing)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;它调用了<code>SSDNet</code>的<code>losses</code>函数，只有一句话</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">losses</span><span class="params">(self, logits, localisations,</span></span></div><div class="line"><span class="function"><span class="params">           gclasses, glocalisations, gscores,</span></span></div><div class="line"><span class="function"><span class="params">           match_threshold=<span class="number">0.5</span>,</span></span></div><div class="line"><span class="function"><span class="params">           negative_ratio=<span class="number">3.</span>,</span></span></div><div class="line"><span class="function"><span class="params">           alpha=<span class="number">1.</span>,</span></span></div><div class="line"><span class="function"><span class="params">           label_smoothing=<span class="number">0.</span>,</span></span></div><div class="line"><span class="function"><span class="params">           scope=<span class="string">'ssd_losses'</span>)</span>:</span></div><div class="line">    <span class="string">"""Define the SSD network losses.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="keyword">return</span> ssd_losses(logits, localisations,</div><div class="line">                      gclasses, glocalisations, gscores,</div><div class="line">                      match_threshold=match_threshold,</div><div class="line">                      negative_ratio=negative_ratio,</div><div class="line">                      alpha=alpha,</div><div class="line">                      label_smoothing=label_smoothing,</div><div class="line">                      scope=scope)</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;它调用的<code>ssd_losses</code>是定义在相同文件中的函数，为了减少说明，使用了网上的有注释的版本，如下所示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment"># =========================================================================== #</span></div><div class="line"><span class="comment"># SSD loss function.</span></div><div class="line"><span class="comment"># =========================================================================== #</span></div><div class="line"><span class="comment">#logits.shape=[(5,38,38,4,21),(5,19,19,6,21),(5,10,10,6,21),(5,5,5,6,21),(5,3,3,4,21),(5,1,1,4,21)]</span></div><div class="line"><span class="comment">#localisations.shape=[(5,38,38,4,4),(5,19,19,6,4),(5,10,10,6,4),(5,5,5,6,4),(5,3,3,4,4),(5,1,1,4,4)],glocalisations同</span></div><div class="line"><span class="comment">#gclasses.shape=[(5,38,38,4),.................], gscores同</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ssd_losses</span><span class="params">(logits, localisations,             </span></span></div><div class="line"><span class="function"><span class="params">               #预测类别, 预测位置</span></span></div><div class="line"><span class="function"><span class="params">               gclasses, glocalisations, gscores,</span></span></div><div class="line"><span class="function"><span class="params">               #ground truth 类别, ground truth 位置, ground truth 分数</span></span></div><div class="line"><span class="function"><span class="params">               match_threshold=<span class="number">0.5</span>,</span></span></div><div class="line"><span class="function"><span class="params">               negative_ratio=<span class="number">3.</span>,</span></span></div><div class="line"><span class="function"><span class="params">               alpha=<span class="number">1.</span>,</span></span></div><div class="line"><span class="function"><span class="params">               label_smoothing=<span class="number">0.</span>,</span></span></div><div class="line"><span class="function"><span class="params">               device=<span class="string">'/cpu:0'</span>,</span></span></div><div class="line"><span class="function"><span class="params">               scope=None)</span>:</span></div><div class="line">    <span class="keyword">with</span> tf.name_scope(scope, <span class="string">'ssd_losses'</span>):</div><div class="line">        lshape = tfe.get_shape(logits[<span class="number">0</span>], <span class="number">5</span>)</div><div class="line">        num_classes = lshape[<span class="number">-1</span>]</div><div class="line">        batch_size = lshape[<span class="number">0</span>]	<span class="comment">#5</span></div><div class="line"> </div><div class="line">        <span class="comment"># Flatten out all vectors!</span></div><div class="line">        flogits = []</div><div class="line">        fgclasses = []</div><div class="line">        fgscores = []</div><div class="line">        flocalisations = []</div><div class="line">        fglocalisations = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(logits)):</div><div class="line">            flogits.append(tf.reshape(logits[i], [<span class="number">-1</span>, num_classes]))</div><div class="line">            fgclasses.append(tf.reshape(gclasses[i], [<span class="number">-1</span>]))</div><div class="line">            fgscores.append(tf.reshape(gscores[i], [<span class="number">-1</span>]))</div><div class="line">            flocalisations.append(tf.reshape(localisations[i], [<span class="number">-1</span>, <span class="number">4</span>]))</div><div class="line">            fglocalisations.append(tf.reshape(glocalisations[i], [<span class="number">-1</span>, <span class="number">4</span>]))</div><div class="line"> </div><div class="line">        <span class="comment">#flogits.shape=[shape=(5×38×38×4,21), shape=(5×19×19×6,21), ......], 共6个feature map的组成</span></div><div class="line">        <span class="comment">#fgclasses.shape=[shape=(5×38×38×4), shape=(5×19×19×6), ......]其它相似</span></div><div class="line"> </div><div class="line">        <span class="comment"># And concat the crap!</span></div><div class="line">        <span class="comment">#logits.shape=(5×38×38×4+5×19×19×6+...+5×1×1×4, 21)</span></div><div class="line">        <span class="comment">#将[flogits[1],flogits[2],...,flogits[i],...]按第一维组合在一起，下同</span></div><div class="line">        logits = tf.concat(flogits, axis=<span class="number">0</span>) </div><div class="line">        </div><div class="line">        gclasses = tf.concat(fgclasses, axis=<span class="number">0</span>)</div><div class="line">        gscores = tf.concat(fgscores, axis=<span class="number">0</span>)</div><div class="line">        localisations = tf.concat(flocalisations, axis=<span class="number">0</span>)</div><div class="line">        glocalisations = tf.concat(fglocalisations, axis=<span class="number">0</span>)</div><div class="line">        dtype = logits.dtype</div><div class="line"> </div><div class="line">        <span class="comment"># Compute positive matching mask...</span></div><div class="line">        pmask = gscores &gt; match_threshold   <span class="comment">#得分&gt;0.5的为正样本(掩码)</span></div><div class="line">        fpmask = tf.cast(pmask, dtype)</div><div class="line">        n_positives = tf.reduce_sum(fpmask) <span class="comment">#正样本数</span></div><div class="line"> </div><div class="line">        <span class="comment"># Hard negative mining...</span></div><div class="line">        no_classes = tf.cast(pmask, tf.int32)</div><div class="line">        predictions = slim.softmax(logits)</div><div class="line">        nmask = tf.logical_and(tf.logical_not(pmask), <span class="comment">#得分&gt;-0.5且&lt;=0.5的样本</span></div><div class="line">                               gscores &gt; <span class="number">-0.5</span>)</div><div class="line">        fnmask = tf.cast(nmask, dtype) </div><div class="line">        </div><div class="line">        <span class="comment">#得分&gt;-0.5且&lt;=0.5的样本在第0类（负样本）处的预测值（softmax）. </span></div><div class="line">        <span class="comment">#nvalues=[[p1],[p2],...,[pN]],N为一个batch中的anchors的总数,</span></div><div class="line">        <span class="comment">#满足score&gt;0.5的样本,pi=0</span></div><div class="line">        nvalues = tf.where(nmask,                     </div><div class="line">                           predictions[:, <span class="number">0</span>],</div><div class="line">                           <span class="number">1.</span> - fnmask)</div><div class="line">                           </div><div class="line">        <span class="comment">#nvalues_flat=[p1,p2,...,pN]</span></div><div class="line">        nvalues_flat = tf.reshape(nvalues, [<span class="number">-1</span>])</div><div class="line">        </div><div class="line">        <span class="comment"># Number of negative entries to select.</span></div><div class="line">        <span class="comment">#负样本数取满足-0.5&lt;score&lt;=0.5和3倍正样本数中的最小值（保证正负样本比例不小于1:3）</span></div><div class="line">        max_neg_entries = tf.cast(tf.reduce_sum(fnmask), tf.int32)</div><div class="line">        n_neg = tf.cast(negative_ratio * n_positives, tf.int32) + batch_size</div><div class="line">        n_neg = tf.minimum(n_neg, max_neg_entries)</div><div class="line"> </div><div class="line">        <span class="comment">#返回-nvalues_flat中最大的k(n_neg)值,和其索引(从0开始),即nvalues_flat中最小的k个值</span></div><div class="line">        val, idxes = tf.nn.top_k(-nvalues_flat, k=n_neg)</div><div class="line">        <span class="comment">#nvalues_flat中最小的k个值中的最大值,对应样本记为Max Negative Hard样本</span></div><div class="line">        max_hard_pred = -val[<span class="number">-1</span>]</div><div class="line">        <span class="comment"># Final negative mask.</span></div><div class="line">        <span class="comment">#最终负样本为置信度小于Max Negative Hard的所有样本</span></div><div class="line">        nmask = tf.logical_and(nmask, nvalues &lt; max_hard_pred)</div><div class="line">        fnmask = tf.cast(nmask, dtype)</div><div class="line"> </div><div class="line">        <span class="comment"># Add cross-entropy loss.</span></div><div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'cross_entropy_pos'</span>):</div><div class="line">            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,</div><div class="line">                                                                  labels=gclasses)</div><div class="line">            </div><div class="line">            <span class="comment">#loss乘正样本掩码得符合条件的正样本损失；损失除以batch_size(这里为5)</span></div><div class="line">            loss = tf.div(tf.reduce_sum(loss * fpmask), batch_size, name=<span class="string">'value'</span>) </div><div class="line">            tf.losses.add_loss(loss)		<span class="comment">#将当前loss添加到总loss集合</span></div><div class="line"> </div><div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'cross_entropy_neg'</span>):</div><div class="line">            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,</div><div class="line">                                                                  labels=no_classes)</div><div class="line">            loss = tf.div(tf.reduce_sum(loss * fnmask), batch_size, name=<span class="string">'value'</span>)</div><div class="line">            tf.losses.add_loss(loss)		<span class="comment">#将当前loss添加到总loss集合</span></div><div class="line"> </div><div class="line">        <span class="comment"># Add localization loss: smooth L1, L2, ...</span></div><div class="line">        <span class="keyword">with</span> tf.name_scope(<span class="string">'localization'</span>):</div><div class="line">            <span class="comment"># Weights Tensor: positive mask + random negative.</span></div><div class="line">            weights = tf.expand_dims(alpha * fpmask, axis=<span class="number">-1</span>) <span class="comment">#位置项损失权重α</span></div><div class="line">            loss = custom_layers.abs_smooth(localisations - glocalisations)</div><div class="line">            loss = tf.div(tf.reduce_sum(loss * weights), batch_size, name=<span class="string">'value'</span>)</div><div class="line">            </div><div class="line">            <span class="comment">#将当前loss添加到总loss集合，最后通过tf.losses.get_total_loss()计算所有的loss</span></div><div class="line">            tf.losses.add_loss(loss)</div></pre></td></tr></table></figure>
<h2 id="六、Data-Augmentation"><a href="#六、Data-Augmentation" class="headerlink" title="六、Data Augmentation"></a>六、Data Augmentation</h2><p>&emsp;&emsp;此处数据增强在tf中有很多辅助函数，而pytorch对ssd的实现中（<a href="https://github.com/amdegroot/ssd.pytorch" target="_blank" rel="external">amdegroot/ssd.pytorch</a>）数据增强的部分都是使用的自己写的函数，先读HSV颜色空间相关内容，占坑。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/CV/" rel="tag"><i class="fa fa-tag"></i> CV</a>
          
            <a href="/tags/Object-Detection/" rel="tag"><i class="fa fa-tag"></i> Object Detection</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/08/Word2Vec-basic/" rel="next" title="word2vec理解">
                <i class="fa fa-chevron-left"></i> word2vec理解
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://ov718qcsg.bkt.clouddn.com/blog/timg.jpg"
               alt="ljm" />
          <p class="site-author-name" itemprop="name">ljm</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives">
            
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/mingming97" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、思路"><span class="nav-number">1.</span> <span class="nav-text">一、思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、default-boxes提取"><span class="nav-number">2.</span> <span class="nav-text">二、default boxes提取</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、Bboxes-Encode"><span class="nav-number">3.</span> <span class="nav-text">三、Bboxes Encode</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、网络结构"><span class="nav-number">4.</span> <span class="nav-text">四、网络结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#五、loss的计算"><span class="nav-number">5.</span> <span class="nav-text">五、loss的计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#六、Data-Augmentation"><span class="nav-number">6.</span> <span class="nav-text">六、Data Augmentation</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <!--<i class="fa fa-heart"></i> -->
    <i class="fa fa-cog" aria-hidden="true"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ljm</span>

  
</div>


  
  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_pv">
    访客数:<span id="busuanzi_value_site_pv">
  </div>

<!--
  <span class="post-meta-divider">|</span>

  <div class="powered-by">由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动</div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">主题 &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.2</div>
-->


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  








  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
